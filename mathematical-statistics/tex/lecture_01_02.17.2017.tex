\section{Лекция 1 от 17.02.2017}
\epigraph{Точность результата не может быть выше точности исходных данных.}{}
\subsection{Предмет математической статистики}
Приступим ко второй части нашего курса~--- к математической статистике. Вообще, 
что это за наука и чем она отличается от теории вероятностей? Для этого надо 
понять, чем занимается математическая статистика. Ранее мы приводили примеры 
задач математической статистики. Из них следует то, что эта наука занимается 
\emph{оцениванием} тех или иных параметров по \emph{эмпирическим} (опытным) 
данным.

В теории вероятностей рассматривались вероятностные пространства \((\Omega, \F, 
\Pr)\), где \(\F\), вообще говоря, никого особо не интересовало. Но, что самое 
главное, было известно \(\Pr\) и задачи, грубо говоря, сводились к чему-то в 
стиле <<восстановить одну вероятностную меру по другой>>. 

В математической статистике же всё устроено по-другому. По сути, она крутится 
вокруг данных. Введём пару определений, связанных с ними:
\begin{definition}
	\emph{Генеральная совокупность}~--- множество всех объектов, 
	относительно которых учёный намерен делать какие-либо выводы при изучении 
	конкретной проблемы.
\end{definition}
\begin{definition}
	\emph{Выборка}~--- это некоторая часть объектов генеральной совокупности, 
	которая выступает в качестве объектов непосредственного изучения.
\end{definition}
\begin{example}
	Если генеральная совокупность~--- это студенты набора 2015-го года, то 
	группа БПМИ151 является выборкой.
\end{example}

Но не всегда по полученным данным можно делать хоть какие-то выводы. Наложим 
определённые условия, которые будут в дальнейшем выполняться по умолчанию. 
Во-первых, данные должны быть \emph{репрезентативными}. Что это значит?
\begin{definition}
	\emph{Репрезентативность}~--- соответствие основных свойств и характеристик 
	выборки характеристикам генеральной совокупности.
\end{definition} 
По сути, репрезентативность позволяет делать выводы о свойствах генеральной 
совокупности по результатам исследования выборки. А что будет, если 
репрезентативности нет? Тогда и выводы будут ложными.
\begin{example}
	Журнал <<Литературный Дайджест>> решил попробовать предсказать результаты 
	президентских выборов 1932-го года. В итоге они смогли с точностью до 
	одного процента предсказать победу Франклина Рузвельта. Воодушевлённые 
	успехом, они решили повторить исследование для выборов 1936-го года. В тот 
	год претендентами выступали Рузвельт и республиканец Альфред Лэндон. То, 
	что устроил <<Литературный Дайджест>>, называется \emph{веерным опросом}: 
	они разослали образцы бюллетеней большому количеству людей, чьи имена были 
	в телефонных справочниках и в списках регистрации транспортных средств. В 
	этот перечень также входили и их подписчики, члены клуба и так далее. 
	
	В итоге было разослано более 10 миллионов таких бюллетеней. Только 2,4 млн. 
	респондентов отослали свои бюллетени назад в редакцию, а 7,6 млн. 
	бюллетеней были утеряны. По полученным бюллетеням журнал предсказал победу 
	Лэндона с \(60\%\) голосов. Однако в реальности оказалось всё ровно 
	наоборот: Рузвельт получил \(61\%\) голосов избирателей, что составило одно 
	из самых больших преимуществ в истории американских президентских выборов. 
	В итоге <<Литературный Дайджест>> вскоре закрылся.
\end{example}

Почему всё пошло не так, как ожидалось? Причина проста~--- выборка была 
непрезентативной. В основном заполненные бюллетени отсылали людьми с достатком 
выше среднего,\footnote{В основном теми, кто мог себе позволить вещи уровня 
телефона или автомобиля. В 30-е года XX-го века это значило достаточно много.} 
а среди них Лэндон был в фаворитах, так как его программа была им выгодна. 

Впрочем, тут ещё сыграло роль то, что на веерные опросы отвечают только самые 
активные. Это называется \emph{смещённостью}, так как мнение смещено (в данном 
случае в сторону более активных граждан).

В 1935-м году Джордж Гэллап основал компанию\footnote{\url{www.gallup.com}}, 
которая занимается изучением общественного мнения и построению предсказаний по 
нему. Но он пользовался принципиально иной схемой: он опрашивал небольшое 
(около десяти тысяч) число человек, после чего уточнял результат различными 
способами и изменял выборку. 

Впрочем, уже полутора-двух тысяч человек достаточно для того, чтобы сделать 
хоть сколько-то достоверный вывод.

Далее, может возникнуть проблема следующего плана: человек отказывается 
отвечать на какой-то вопрос из опроса (не важно, по какой причине). В итоге 
получается \emph{выборка с неполными данными}. Но наш курс слишком короткий, 
поэтому мы не будем рассматривать выборки с неполными данными, как и проверку 
репрезентативности.

Вернёмся от слов к математике. В теории вводились вероятностные пространства, 
здесь же вводятся статистические структуры.
\begin{definition}
	\emph{Статистическая структура}~--- это тройка \((\X, \F, \mathcal{P})\), 
	где \(\X\)~--- это \emph{выборочное пространство}, \(\F\)~--- 
	\(\sigma\)-алгебра над выборочным пространством, а \(\mathcal{P}\)~--- 
	семейство 
	вероятностных мер.
\end{definition}

Теперь надо прояснить суть каждого элемента тройки. Допустим, что мы провели 
эксперимент. Под \emph{экспериментом} в статистике подразумевается любой 
процесс получения данных, все возможные исходы которого могут быть указаны 
заранее и действительный исход которого является возможным. Обозначим эти 
данные за \(X\) и будем в дальнейшем называть их \emph{выборкой}. Тогда 
\emph{выборочное пространство} содержит все возможные реализации \(x\) 
(результаты измерений) \(X\). Так как в математической статистике 
рассматриваются эксперименты такие, что их исход случаен, то можно считать, что 
\(X\)~--- это случайная величина (или вектор, в зависимости от размерности 
\(X\)) на \(\X\).

\begin{remark}
	В дальнейшем мы будем считать \emph{выборкой} и саму выборку \(X\), и 
	реализацию выборки \(x\). Смысл будет понятен из контекста.
\end{remark}

Со вторым элементом всё относительно понятно~--- суть та же, что и для 
вероятностных пространств. Теперь перейдём к третьему элементу, который 
кардинально отличается от того, что было в теории вероятностей. Дело в том, что 
при проведении эксперимента распределение \(F_{X}\) случайной величины \(X\) 
редко бывает известно полностью. Часто до начала эксперимента можно утверждать 
только то, что \(F_{X}\) лежит в каком-то заданном классе распределений 
\(\mathcal{P}\) на выборочном пространстве \(\X\).

Основной вопрос математической статистики, по сути, является обратным к задаче 
теории вероятностей: как построить вероятностную меру по результатам 
эксперимента так, чтобы она наиболее <<хорошо соответствовала>> выборке? Но для 
ответа на этот вопрос необходимо понять, что это значит~--- <<хорошо 
соответствовать>> выборке. Ведь если нам в рекламе скажут, что <<она 
великолепна~--- мы проверили>>, то можно считать, что ничего про эту марку так 
и не рассказали.

Хорошо, мы провели эксперимент и получили какие-то данные. Что делать дальше? 
Далее проводится \emph{первичный статистический анализ}. 

Как известно из курса теории вероятностей, случайная величина задаётся её 
функцией распределения, характеристической функцией или вероятностной мерой. 
Допустим, что есть случайная величина \(\xi\), заданная на некотором 
вероятностном пространстве и мы проводим повторные наблюдения над ней. Тогда 
выборкой будет случайный вектор \(X = (X_{1}, \dots, X_{n})\), где \(n\)~--- 
это число проведённых экспериментов, а \(X_{i}\)~--- независимые и одинаково 
распределённые случайные величины, причём \(X_{i} \eqdist \xi\). Последнее 
условие в математической статистике часто пишут так: \(X\) из 
\(\mathcal{L}(\xi)\).\footnote{\(\mathcal{L}\) for Law.}

Пусть при экспериментах получилась реализация выборки \(x = (x_{1}, \dots, 
x_{n})\). Тогда введём следующее определение:

\begin{definition}
	\emph{Выборочным распределением} по реализации выборки \(x = 
	(x_{1}, \dots, x_{n})\) называется функция 
	\[
		F_{n}(y) = \frac{1}{n}\sum_{k = 1}^{n}\mathrm{I}\{x_{i} \leq y\}.
	\]
\end{definition}

Будем считать, что \(x\) является реализацией \emph{повторной выборки} \(X = 
(X_{1}, \dots, X_{n})\) из \(\mathcal{L}(\xi)\). Теперь заменим реализацию 
выборки на саму выборку. Тогда выборочное распределение превратится в так 
называемую \emph{эмпирическую функцию распределения}. Понятно, что она является 
случайной величиной и
\[
	\E{F_{n}(y)} = \frac{1}{n}\sum_{k = 1}^{n}\E{\mathrm{I}\{X_{i} \leq 
	y\}} = F_{\xi}(y).
\]

Таким образом, эмпирическая функция распределения является \emph{несмещённой 
оценкой} теоретической функции распределения. Смысл этих слов будет понятен 
несколько позднее.

Теперь докажем следующий факт:
\begin{theorem}
	Эмпирическая функция распределения сходится к теоретической почти наверное: 
	\(F_{n}(y) \asto F_{\xi}(y)\) при \(n \to \infty\).
\end{theorem}
\begin{proof}
	Пусть \(\eta_{i} = \mathrm{I}\{X_{i} \leq y\}\). Тогда \(\eta\) 
	независимы в совокупности и одинаково распределены, причём \(\E{\eta_{i}} = 
	\Pr{X_{i} \leq y} = F_{\xi}(y)\). Так как \(F_{n}(y) = (\eta_{1} + \dots + 
	\eta_{n})/n\) и \(\E|\eta_{i}| \leq 1\), то по усиленному закону больших 
	чисел в форме Колмогорова
	\[
		F_{n}(y) = \frac{\eta_{1} + \dots + \eta_{n}}{n} \asto \E{\eta_{1}} = 
		F_{\xi}(y). \qedhere
	\]
\end{proof}

Однако есть теорема, которая делает эту сходимость ещё более сильной. Её мы 
сформулируем без доказательства:
\begin{theorem}[Гливенко, Кантелли]
	Пусть \(X_{1}, \dots, X_{n}, \dots\)~--- бесконечная выборка из 
	распределения, задаваемого функцией распределения \(F_{\xi}\). Далее, пусть 
	\(F_{n}(y)\)~--- это эмпирическая функция распределения, построенная на 
	первых \(n\) элементах выборки. Тогда
	\[
		\Pr{\lim\limits_{n \to \infty}\sup\limits_{y \in \R} |F_{n}(y) - F(y)| 
		= 0} = 1.
	\]
\end{theorem}

\subsection{Гистограммы и Q-Q графики}
Хотя мы и получили хорошую оценку функции распределения, данная информация 
недостаточно наглядна для первичного анализа. Поэтому рассмотрим два метода 
исследования распределения: \emph{гистограммы} и \emph{Q-Q графики}. Начнём с 
гистограмм.

Пусть в результате эксперимента мы получили какую-то реализацию \((x_{1}, 
\dots, x_{n})\) выборки из \(\mathcal{L}(\xi)\). Отсортируем реализацию по 
возрастанию: \(x_{(1)} \leq x_{(2)} \leq \dots \leq x_{(n)}\). Тогда можно 
сказать, что вся реализация лежит в \([x_{(1)}, x_{(n)}]\). Сама гистограмма 
строится следующим образом: этот отрезок делят на \(k\) частей \(A_{1}, \dots, 
A_{k}\), называемых \emph{карманами} или \emph{интервалами группировки}. 
\footnote{Вообще говоря, они не обязаны быть равны по длине, но по умолчанию 
будем считать, что отрезок делится на равные части.} Далее, пусть \(v_{i}\)~--- 
число элементов реализации, попавших в \(i\)-й карман. Тогда
\[
	v_{i} = \sum_{k = 1}^{n} \mathrm{I}\{x_{i} \in A_{i}\}.
\]

Теперь на каждой части \(A_{k}\) строим прямоугольник так, что площадь всех 
прямоугольников должна быть равна единице. Пусть \(l_{i}\) и \(h_{i}\)~--- это 
длина \(i\)-го кармана и высота \(i\)-го прямоугольника соответственно. Тогда
\[
	h_{i} = \frac{v_{i}}{nl_{i}}.
\]

Получаемая фигура и называется гистограммой.

Теперь опишем Q-Q графики. Это название есть сокращение от 
<<квантиль-квантиль график>>. Но что такое квантиль? Вообще говоря, это 
значение, которое случайная величина не превосходит с заданной вероятностью. 
\begin{definition}
	\emph{Квантилью порядка} \(\alpha\) случайной величины \(\xi\) называется
	\[
		x_{\alpha} = \inf\{x \in \R : F_{\xi}(x) \geq \alpha\}.
	\]
\end{definition}

Немного поясним это определение. Если \(\xi\) имеет монотонно возрастающее 
распределение, то квантиль порядка \(\alpha\) однозначно задаётся уравнением 
\(F_{\xi}(x_{\alpha}) = \alpha\). Если же у функции распределения есть участок 
постоянства, где она принимает значение \(\alpha\), то в качестве квантили 
порядка \(\alpha\) берётся минимальное на отрезке постоянства значение \(x\). 
Если в рассматриваемой точке функция терпит разрыв, то берётся значение справа.

А сам график строится достаточно просто. Пусть есть реализация \((x_{1}, \dots, 
x_{n})\) выборки из \(\mathcal{L}(\xi)\) и известно распределение \(\xi\). 
Отсортируем значения в реализации по возрастанию: \(x_{(1)} \leq x_{(2)} \leq 
\dots \leq x_{(n)}\). Тогда \(x_{(i)}\) будет служить квантилью порядка \(i/n\) 
для эмпирического распределения реализации. Осталось посчитать квантили 
порядков \(i/n\) для теоретического распределения \(\mathcal{L}(\xi)\). На 
графике откладываются точки, координаты которых~--- это квантили одного порядка 
для эмпирического и для теоретического распределений. Если распределения 
близки, то на графике будет изображено нечто, похожее на биссектрису первого и 
третьего координатных углов. Если же на графике изображена <<прямая>>, не 
совпадающая с биссектрисой, то распределение угадано верно, а параметры не 
совпадают.

\subsection{Стохастический подход и гипотезы}
Теперь вернёмся к основной задаче математической статистики. Мы говорили, что 
нам нужно каким-то образом <<подогнать>> вероятностную меру.

Допустим, что мы посмотрели на котировки биржи в определённые моменты времени и 
сохранили стоимость акций. Таким образом мы получили реализацию \((f(t_{1}), 
\dots, f(t_{n}))\), где \(t_{i}\)~--- это моменты времени. Но это всё было 
измерено в прошлом. А как посмотреть историю будущего? Другими словами, как 
предугадать то, как себя будет вести стоимость акций дальше?

Для этого мы рассмотрим так называемый \emph{стохастический подход}. Пусть 
\(X\)~--- это цена акции. Нам нужно по имеющимся данным предположить, какое 
распределение имеет \(X\). Например:
\begin{hypothesis}
	\(X\) имеет логнормальное распределение: \(\ln X \sim \mathcal{N}(a, 
	\sigma^2)\) для каких-то \(a\) и \(\sigma^2\).
\end{hypothesis}

Гипотезы о виде распределения называются \emph{основными} (или 
\emph{нулевыми}) и обычно обозначаются \(H_{0}\).

Теперь мы из одной проблемы получили две:
\begin{enumerate}
	\item Не очень понятно, как проверять гипотезу.
	\item Мы не знаем параметров распределения. Так что сначала нам необходимо 
	найти точечные оценки: \(a^{*} = a^{*}(x_{1}, \dots, x_{n})\) и 
	\((\sigma^{2})^{*} = (\sigma^{2})^{*}(x_{1}, \dots, x_{n})\).
\end{enumerate}

В дальнейшем нам будут нужны две оценки параметров случайной величины: для 
среднего и для дисперсии. Выпишем их:
\begin{align*}
	\overline{X} &= \frac{1}{n}\sum_{k = 1}^{n} x_{k} \text{ --- выборочное 
	среднее,} \\
	S^2 &= \frac{1}{n}\sum_{k = 1}^{n} (x_{k} - \overline{X})^2 \text{ --- 
	выборочная дисперсия.}
\end{align*}