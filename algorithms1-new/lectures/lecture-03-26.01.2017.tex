\documentclass[../main.tex]{subfiles}

%Sample lecture


\begin{document}
	\section{Лекция 3. Quick sort, оптимальность сортировки слиянием}
	CAUTION! RECURTION IS HERE!
	
	
	В стратегии \textit{разделяй и властвуй}, которая используется во многих алгоритмах обработки данных, есть 3 четко выделяемые фазы.
	\begin{enumerate}
		\item \textit{Деление}. Задача размера $n$ делится на несколько меньших подзадач, подобных исходной.
		
		\item \textit{Решение}. Каждая из подзадач рекурсивно решается тем же алгоритмом. При этом важно, чтобы рекурсия остановилась на элементарном размере подзадачи. Под элементарным подразумевается, что такую подзадачу можно решить за константное время.
		
		\item \textit{Слияние}. Полученные результаты сливаются в одно общее решение.		
	\end{enumerate}
	
	На примере Merge Sort'a это выглядит следующим образом:
	\begin{center}
		\begin{tabular}{c|c}
			Деление &
			$A_1 = A[:\frac{n}{2}]$ \\
			&
			$A_2 = A[\frac{n}{2}:]$
			\\ \hline
			Решение &
			$A_1' = mergesort(A_1)$
			\\
			&
			$A_2' = mergesort(A_2)$
			\\ \hline
			Слияние &
			\textbf{return} $merge(A_1, A_2)$
		\end{tabular}
	\end{center}
	
	С ним все просто и понятно. Поделили - решили - объединили. Но существуют и другие алгоритмы сортировки. Один из самых знаменитых из них - \textit{Quick Sort}.
	
	
	
	\subsection{QuickSort}
	
	Идея алгоритма в чем-то схожа с сортировкой слиянием: мы делим массив на две половины специальным образом и применяем алгоритм к каждой из частей рекурсивно. Главное отличие - алгоритм не имеет отдельной процедуры слияния и тратит всего $O(1)$ памяти, вместо совершенно нерационального потребления Merge Sort'ом.
	
	\textit{Делить} задачу мы будем следующим образом: возьмем \textit{опорный} элемент $p \in A$, и приведем массив в следующее состояние:
	
	\begin{center}
		\begin{tikzpicture}
			\matrix[matrix of math nodes, row sep=2mm] (M) {
				& & A_1 & & & & A_2 &  \\
				\leftbracket & A[i_0] & \ldots & A[i_{k}] &  p  & A[i_{kh + 1}] & \ldots & A[i_n] &  \rightbracket \\
				& & \leqslant p & & & & >p &  \\
			};
		\end{tikzpicture}
	\end{center}
	
	Словами: делим массив на части, в каждой из которых все элементы либо больше или равны опорного, либо меньше него.
	
	Затем рекурсивно запускаем алгоритм от $A_1$ и $A_2$, пока не дойдем до задачи размера 1. Утверждается, что когда рекурсия остановится, задача будет решена, и массив $A$ будет отсортирован.
	
	Этот алгоритм полностью зависит от процедуры выбора опорного элемента. В идеальном случае надо брать медиану на каждом шаге, тогда мы будем делить массив ровно на две части, и время работы $T(n)$ будет выражаться так:
	\[
	T(n) = T\left(\frac{n}{2}\right) + T\left(\frac{n}{2}\right) + O(n) = \Theta(n\log n)
	\]
	
	В конце стоит $O(n)$, потому что нам нужно во время перемещения элементов посмотреть хотя бы на каждый из них. 
	
	Но если мы хотим сделать так, чтобы такая асимптотика достигалась постоянно, нужно искать медиану, а это как минимум $O(n)$, если повезет, но асимптотика тогда увеличится. Нерационально. 
	
	Самая главная часть в алгоритме называется \textit{Partition}, именно она ответственна за разделение массива. Приведем псевдокод оптимальной по памяти версии, которая сортирует inline. 
	
	\begin{algorithm}[H]
		\caption{Partition}
		\begin{algorithmic}[1]
			\Require Массив $A$, границы разделяемой части $l, r$.
			\Function{partition}{$A, l, r$}
				\State $i := l$
				\For{$j := l + 1$ \textbf{to} $r$}
					\If{$A[j] \leqslant A[l]$}
						\State swap($A[i], A[j]$)
						\State $i$ += 1
					\Else
						\State \textbf{continue}
					\EndIf
				\EndFor
				\State swap($A[l], A[i]$)
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	
	Эта версия алгоритма за опорный элемент берет левую границу интервала. Получается такой переход:
	
	\begin{center}
		\begin{tikzpicture}
		\matrix[matrix of math nodes, row sep=2mm] (M) {
			\leftbracket A[0] & \ldots & A[l] & & & \ldots &\ldots & & & A[r]& \ldots& A[n] \rightbracket \\
			\leftbracket A[0] & \ldots & A[i_0] & \ldots & A[i_{\frac{k}{2}}] & A[l] & A[i_{{\frac{k}{2}}+1}] & \ldots & A[i_k] & A[r]& \ldots& A[n] \rightbracket \\
		};
		\end{tikzpicture}
	\end{center}
	
	\begin{time}
		Посчитаем для худшего случая - когда наш массив отсортирован в обратном порядке, значит операция Partition будет вызываться от массивов, каждый раз размером на 1 меньше. Получается 
		\[
		T(n) = T(n - 1) + O(n) = \sum_{i = 1}^n (n - i) = O(n^2)
		\]
		
		В лучшем случае время будет как у Merge Sort'a - $O(n\log n)$
	\end{time}
	
	Этот алгоритм есть пример тех алгоритмов, для которых лучше рассматривать время в среднем случае. 
		
	\begin{definition}
		Назовем элемент \textit{центральным}, если в отсортированном массиве он больше первой четверти элементов и меньше последней четверти элементов.
	\end{definition}
	
	Такой элемент оказывается очень удобным, так как его можно брать за опорный, причем он гарантированно разобьет массив на непустые части. Искать такой элемент можно \textit{детерминированно}, или точно вычитывать по какому-то алгоритму, но сложность такого выбора будет $O(n)$. Мы же будем использовать \textit{вероятностный} подход, или брать случайный элемент в массиве. 
	
	С этого момента Quick Sort становится \textit{рандомизированным} алгоритмом, так как на одном и том же входе шаги алгоритма неизвестны заранее. При этом становится легко считать его сложность
	
	\begin{time}
		Построим дерево исполнения алгоритма для случая, когда он разбивает задачи на подзадачи меньшие, чем $\frac{3}{4}$.
		
		\begin{center}
			\begin{tikzpicture}
				\begin{scope}[every node/.style={circle,thick,draw}]
					\node[label=\large$ n $] (top) at (10, 10) {};
					
					\node[label=left:\Large $ \leqslant \frac{3n}{4}$] (mid-left) at (7, 8) {};
					\node[label=right:\Large $ \leqslant \frac{3n}{4}$] (mid-right) at (13, 8) {};
					
					\node (bot-left) at (5, 6) {};
					\node[label=right:\Large $ \leqslant (\frac{3n}{4})^2$] (bot-right) at (9, 6) {};
				\end{scope}
				
				\begin{scope}[>={Stealth[black]}, every edge/.style={draw=black,very thick}]
					\path [->] (top) edge (mid-left);
					\path [->] (top) edge (mid-right);
					
					\path [->] (mid-left) edge (bot-left);
					\path [->] (mid-left) edge (bot-right);
				
				\end{scope}
			\end{tikzpicture}
		\end{center}
		
		На $j$ подзадачу тратится время $O((\frac{3}{4})^jn)$, на $j$ подзадач - $O((\frac{4}{3})^{j + 1})$. В итоге получаем, что среднее время на все подзадачи
		\[
		T(n) = 	O\left(
					\left(
						\frac{3}{4}
					\right)^jn
					\right)
				\cdot 
				O\left(
					\left(
						\frac{4}{3}
					\right)^j
				\right)
		\]
		
		Прологарифмируем и получим, что
		\[
		T(n) = O(n\log n)
		\]
	\end{time}
	
	На практике обычно Quick Sort работает быстрее, чем Merge Sort, несмотря на одинаковую асимптотику. Связано это с тем, что QS сортирует на месте, в исходном массиве, MS тратит время на работу с памятью, так как ему нужно еще $O(n)$ памяти.
	
	
	\begin{remark}
		При реализации алгоритма Partition можно вместе с границами передавать опорный элемент, переписав тело цикла. Получим процедуру, которая будет делить в интервале массив на две части, которые меньше и больше опорного.
	\end{remark}
	
	\subsection{Оптимальность сортировки слиянием}
	
	Утверждается, что время работы сортировки слиянием асимптотически самое маленькое.
	
	\begin{theorem}
		Нельзя отсортировать массив быстрее, чем за $O(n \log n$), если разрешено использовать только сравнение элементов и их перемещение.
	\end{theorem}
	
	
	\begin{proof}
		Рассмотрим массив $A$. Пусть ответом на задачу будет такая подстановка $\sigma$, что после ее применения массив окажется отсортирован.
		
		Рассмотрим \textit{дерево решений} некоторого абстрактного алгоритма сортировки. Пусть вершиной будет операция сравнения, ребром - ее исход, а листом - искомая перестановка. Такое дерево можно построить для каждого алгоритма. 
		
		Покажем пример такого дерева для сортировки массива длины 3:
		\begin{center}
			\begin{tikzpicture}
			\begin{scope}[every node/.style={circle,thick,draw}]
				\node (top) at (10, 10) {$1 < 3$};
				
				\node (2-1) at (6, 	8) 	{$1 < 2$};
				\node (2-2) at (14, 8) 	{$1 < 2$};
				
				\node (3-1) at (4, 	6) 	{$2 < 3$};
				\node (3-4) at (16, 6) 	{$2 < 3$};
			\end{scope}
			
			\begin{scope}[every node/.style={circle,draw}]
				\node (3-2) at (8, 6) 	{$(213)$};
				\node (3-3) at (12, 6) 	{$(312)$};
				
				\node (4-1) at (2, 4) 	{$(123)$};
				\node (4-2) at (6, 4) 	{$(132)$};
				\node (4-3) at (14, 4) 	{$(231)$};
				\node (4-4) at (18, 4) 	{$(321)$};
			\end{scope}
			
			\begin{scope}[>={Stealth[black]}, every edge/.style={draw=black}]
			
				\path [->] (top) edge node[midway, above left] 	{да} 	(2-1);
				\path [->] (top) edge node[midway, above right] {нет} 	(2-2);
				
				\path [->] (2-1) edge node[midway, above left] 	{да} 	(3-1);
				\path [->] (2-1) edge node[midway, above right] {нет}	(3-2);
				
				\path [->] (2-2) edge node[midway, above left] 	{да} 	(3-3);
				\path [->] (2-2) edge node[midway, above right] {нет} 	(3-4);
				
				\path [->] (3-1) edge node[midway, above left] 	{да} 	(4-1);
				\path [->] (3-1) edge node[midway, above right] {нет} 	(4-2);
				
				
				\path [->] (3-4) edge node[midway, above left] 	{да} 	(4-3);
				\path [->] (3-4) edge node[midway, above right] {нет} 	(4-4);
			\end{scope}
			\end{tikzpicture}
		\end{center}
		
		Временем работы всего алгоритма будет высота этого дерева $h$. Число листьев -- $n!$.
		\[
		n! \leqslant 2^h
		\]
		\[
		\log_2n! \leqslant h
		\]
		\[
		h \geqslant \log_2n! \geqslant \log_2 \left(\frac{n}{2}\right)^{\frac{n}{2}} = \frac{n}{2} \log_2(n) - 1 = \Omega(n\log n).
		\]
	\end{proof}
	
	
	
	
	
	
	
	
	
	
	\pagebreak	
\end{document}