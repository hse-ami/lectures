\section{Лекция от 09.09.2016}
\subsection{Введение. Принцип устойчивости частоты}
Чем занимается теория вероятностей? Она изучает \emph{случайные} явления. Допустим, мы провели какой-либо эксперимент. Можем ли мы что-то заранее сказать о результате?
\begin{itemize}
    \item Если да, то результат называют \emph{детерминированным}. Пример такого эксперимента~--- выбрасывание кирпича из окна. Очевидно, что кирпич упадёт на землю\footnote{Если его не запустили с первой космической скоростью, конечно.} и результат предопределён. Такие задачи изучают в той же линейной алгебре или где-либо ещё, но не в теории вероятностей.
    \item А теперь предположим, что заранее сказать, каков будет результат, невозможно. Например, точно сказать, какой стороной упадёт подброшенная монетка, вряд ли получится. Тогда результат называют \emph{недетерминированным}. Именно задачи с недетерминированным результатом и изучаются в теории вероятностей.
\end{itemize}
Небольшое историческое отступление~--- вообще говоря, теория вероятностей появилась в связи с изучением азартных игр наподобие рулетки ещё в средних веках. Но тогда она представляла собой скорее набор эмпирических фактов, чем полноценную науку. Теория вероятностей стала такой, какой она является сейчас, лишь в XX веке благодаря трудам А.Н. Колмогорова.

Хорошо, а как изучаются случайные процессы? Ну выпала решка, и что? На самом деле теория вероятностей не о единичных экспериментах, а об \emph{асимптотике}. Это значит следующее: если проводить серию одинаковых экспериментов, то теория вероятностей поможет предсказать частоту, с которой будет появляться какой-либо ответ.

Теория вероятностей держится на крайне важном \emph{принципе устойчивости частоты}. Перед тем, как ввести формальное определение, рассмотрим пару экспериментов, связанных с подбрасыванием монетки:
\begin{itemize}
    \item В XVIII веке Жорж-Луи Леклерк де Бюффон провёл эксперимент, подбросив монетку 4040 раз. Из них в 2048 бросках выпал герб. В итоге частота составила около 0.506.
    \item В XIX веке пошли ещё дальше --- Карл Пирсон подбросил монетку 24000 раз.\footnote{Оставим вопрос о том, как он не поленился провернуть это, без ответа.} У него получилось так, что герб выпал 12012 раз. В итоге частота составила 0.5005.
\end{itemize}
Отсюда видно, что эксперименты дают частоту, близкую к \(1/2\).

Неформально говоря, принцип формулируется так: если мы проводим серию одинаковых экспериментов, то количество появлений одного определённого ответа при делении на число экспериментов сходится к некоторому числу \(p \in [0, 1]\). Теперь можно ввести формальное определение.
\begin{frequency-stability}
    Пусть \(A\)~--- некоторое событие, а \(v_{n}(A)\)~--- число экспериментов, в которых происходит событие \(A\) среди первых \(n\). Тогда \[\lim_{n \to \infty}\frac{v_{n}(A)}{n} = p,\quad p \in [0, 1].\]
\end{frequency-stability}
Получаемое число \(p\) называют \emph{вероятностью} события \(A\) и обозначают \(\Pr(A)\). Например, \(\Pr(\text{встретить живого динозавра на улице}) = 0\), так как они все вымерли.

\subsection{Вероятностное пространство. Простейшие свойства вероятности}
Именно после введения этого понятия Колмогоровым теория вероятностей перестала быть прежней. Введём определение для дискретного случая (общий оставим на потом):
\begin{definition}
    \emph{Дискретным вероятностным пространством} называется пара \((\Omega, \Pr)\), где \(\Omega\)~--- \emph{множество элементарных исходов}, а \(\Pr\)~--- \emph{вероятность} на \(\Omega\).
\end{definition}

Множество элементарных исходов \(\Omega\)~--- некоторое конечное или счётное множество. Элемент \(\omega \in \Omega\) называют \emph{элементарным исходом}. Полагается, что в случайном эксперименте обязательно получается один и только один элементарный исход.

Примеры множеств элементарных исходов:
\begin{enumerate}
    \item \(\Omega = \left\{\text{О}, \text{Р}\right\}\)~--- бросок монеты.
    \item \(\Omega = \left\{\omega_1, \ldots, \omega_6\right\}\), где \(\omega_i = \{\)выпало \(i\) очков\(\}\)~--- бросок игрального кубика.
    \item \(\Omega = \left\{\omega_1, \ldots, \omega_n, \ldots \right\}\), где \(\omega_i = \{\)на данный момент горит \(i\) зданий\(\}\)~---  предсказание пожаров в городе.
\end{enumerate}

\begin{definition}
    Подмножество \(A \subseteq \Omega\) называется \emph{событием} на вероятностном пространстве \((\Omega, \Pr)\).
\end{definition}
Пример события: пусть подбрасывают игральную кость, и \(A\) = \(\{\)выпало чётное число очков\(\}\). Тогда \(A = \left\{\omega_2, \omega_4, \omega_6 \right\}\).

\begin{definition}
    Отображение \(\Pr : \Omega \to [0, 1]\) называют \emph{вероятностью}\footnote{В общем случае вероятность ещё могут называть \emph{вероятностной мерой}.}, если \(\sum\limits_{\omega \in \Omega} \Pr(\omega) = 1.\) В случае счётного множества \(\Omega\) данный ряд должен сходиться абсолютно.
\end{definition}

Пусть у нас есть некоторое событие \(A\) на вероятностном пространстве \((\Omega, \Pr)\). Как посчитать его вероятность?
\begin{definition}
    \emph{Вероятностью события} \(A \subseteq \Omega\) называют \(\Pr(A) = \sum\limits_{\omega \in A} \Pr(\omega).\)
\end{definition}

\begin{definition}
    Пусть \(A\)~--- некое событие. Тогда \emph{дополнением} к событию \(A\) называют событие \(\overline{A} = \Omega \setminus A\).
\end{definition}

Перед тем, как идти дальше, напомним определение дизъюнктного объединения.
\begin{definition}
    Пусть есть множества \(A_1, A_2, \ldots, A_n\). Тогда \emph{дизъюнктным объединением} множеств называют объединение попарно непересекающихся ``копий'' множеств: \[\bigsqcup_{i = 1}^{n} A_i = \bigcup_{i = 1}^{n} \left\{(x, i) \mid x \in A_i\right\}.\] В нашем случае полагается, что если пишут дизъюнктное объединение, то множества попарно не пересекаются.
\end{definition}

Рассмотрим некоторые свойства вероятности.
\begin{theorem}[Простейшие свойства вероятности]
    Для любого дискретного вероятностного пространства \((\Omega, \Pr)\) выполняется следующее:
    \begin{enumerate}
        \item \(\Pr(\Omega) = 1\), \(\Pr(\emptyset) = 0\).
        \item Конечная аддитивность: \(\Pr\left(\bigsqcup\limits_{i = 1}^{n} A_i\right) = \sum\limits_{i = 1}^{n} \Pr(A_i)\).
        \item \(\Pr(A) + \Pr(\overline{A}) = 1\).
        \item \(\Pr(A \cup B) = \Pr(A) + \Pr(B) - \Pr(A \cap B)\).
        \item Для любого набора событий \(A_1, A_2, \ldots, A_n\) \(\Pr\left(\bigcup\limits_{i = 1}^{n} A_i\right) \leq \sum\limits_{i = 1}^{n} \Pr(A_i)\).
        \item Счётная аддитивность: \(\Pr\left(\bigsqcup\limits_{i = 1}^{\infty} A_i\right) = \sum\limits_{i = 1}^{\infty} \Pr(A_i).\)
    \end{enumerate}
    Последнее свойство выполняется только для счётного \(\Omega\).
\end{theorem}
\begin{proof}
    Распишем доказательства для каждого пункта по отдельности:
    \begin{enumerate}
        \item \(\Pr(\Omega) = 1\) следует из определения вероятности, а \(\Pr(\emptyset) = 0\) следует из определения вероятности события.
        
        \item Случай с конечным множеством \(\Omega\) очевиден. Тогда положим, что \(\Omega\) счётно, то есть \(\Omega = \left\{\omega_i \mid i \in \N \right\}\).
        
        Пусть есть некоторое событие \(A\). Тогда представим его вероятность в удобном для нас виде:
        \[\Pr(A) = \sum_{\omega \in A} \Pr(\omega) = \sum_{i\,:\,\omega_i \in A} \Pr(\omega_i) = \lim_{N \to \infty}\ \sum_{\substack{i\,:\, \omega_i \in A\\i < N}} \Pr(\omega_i).\]
        Теперь распишем вероятность дизъюнктного объединения событий \(A_1, A_2, \ldots, A_n\):
        \begin{multline*}
        \Pr\left(\bigsqcup_{i = 1}^{n} A_i\right) = \sum_{\omega\,\in\,\bigsqcup A_i} \Pr(\omega) = \lim_{N \to \infty} \left(\sum_{\substack{i\,:\,\omega_i\,\in\,\bigsqcup A_i\\i < N}} \Pr(\omega_i)\right) = \lim_{N \to \infty} \sum_{i = 1}^{n} \sum_{\substack{j\,:\,\omega_j\,\in\,A_i\\j < N}} \Pr(\omega_j) = \\ = \sum_{i = 1}^{n} \lim_{N \to \infty} \sum_{\substack{j\,:\,\omega_j\,\in\,A_i\\j < N}} \Pr(\omega_j) = \sum_{i = 1}^{n} \Pr(A_i).
        \end{multline*}
        
        \item Согласно второму пункту, \(1 = \Pr(\Omega) = \Pr(A \cup \overline{A}) = \Pr(A) + \Pr(\overline{A})\).
        
        \item Так как \(A \cup B = A \cup (B \setminus A)\) и \(A \cap (B \setminus A) = \emptyset\), то \(\Pr(A \cup B) = \Pr(A) + \Pr(B \setminus A)\). Далее, заметим, что \(B \setminus A = B \setminus (A \cap B)\). Тогда \(\Pr(A \cup B) = \Pr(A) + \Pr(B \setminus (A \cap B))\).
        
        Рассмотрим второй член. Заметим, что \(\Pr(A \cap B) + \Pr(B \setminus (A \cap B)) = \Pr(B)\).
        Тогда получаем, что \(\Pr(A \cup B) = \Pr(A) + \Pr(B) - \Pr(A \cap B)\).
        
        \item Докажем это утверждение по индукции. База была доказана в пункте 4 (так как \(\Pr(A \cap B) \geq 0\)). Теперь рассмотрим шаг индукции. Пусть утверждение верно для какого-то \(m\). Тогда
        \(\Pr\left(\bigcup\limits_{i = 1}^{m + 1} A_i\right) \leq \Pr(A_{m + 1}) + \Pr\left(\bigcup\limits_{i = 1}^{m} A_i\right) \leq \sum\limits_{i = 1}^{m + 1} \Pr(A_i)\).
        
        \item За доказательством этого пункта обращайтесь к учебнику матанализа на тему частичных сумм и абсолютной сходимости.\footnote{На самом деле я попробую найти доказательство. Когда-нибудь. Но не сейчас. (А.Х.)}
    \end{enumerate}
\end{proof}

\subsection{Классическая модель. Примеры}
Пусть \((\Omega, \Pr)\)~--- некоторое конечное вероятностное пространство, при этом все элементарные исходы равновероятны. Тогда легко посчитать вероятность элементарного исхода: \(\Pr(\omega) = \frac{1}{|\Omega|}\) для всех \(\omega \in \Omega\). Такую модель называют \emph{классической}.

Как посчитать вероятность события в классической модели? Очень просто: \(\Pr(A) = \frac{|A|}{|\Omega|}\) для всех \(A \subseteq \Omega\).

Рассмотрим некоторые примеры классических моделей.
\begin{enumerate}
    \item Бросок монетки. В таком случае \(\Omega = \{\text{О}, \text{Р}\}\) и \(\Pr(\text{О}) = \Pr(\text{Р}) = \frac{1}{2}\).
    
    \item Бросок двух монеток. С этой моделью связано одно заблуждение Д'Аламбера. Он рассуждал следующим образом: так как \(\Omega = \{\text{ОО}, \text{РР}, \text{ОР}\}\), то \(\Pr(\text{ОО}) = \Pr(\text{РР}) = \Pr(\text{ОР}) = \frac{1}{3}\). Но это опровергается экспериментами. И как это исправить? Есть два варианта:
    \begin{enumerate}
        \item Можно сказать, что модель не является классической и поправить вероятности: \(\Pr(\text{ОО}) = \Pr(\text{РР}) = \frac{1}{4}\), \(\Pr(\text{ОР}) = \frac{1}{2}\).
        \item А можно просто изменить множество элементарных исходов. Начнём учитывать порядок выпадения: \(\Omega = \{\text{ОО}, \text{РР}, \text{ОР}, \text{РО}\}\). Такая модель уже является классической.
    \end{enumerate}
    Рассуждая в стиле Д'Аламбера, можно прийти к выводу, что вероятность встретить живого динозавра на улице равна \(\frac{1}{2}\), ведь его можно либо встретить, либо не встретить.
    
    \item Бросок \(n\) монет. В таком случае вероятностное пространство будет устроено следующим образом:
    \(\Omega = \left\{\omega = (\omega_1, \omega_2, \ldots, \omega_n) \mid \omega_i \in \left\{\text{О}, \text{Р}\right\}\right\}\). Легко понять, что в данной модели \(2^n\) элементарных исходов.
    \begin{remark}
        Вероятностное пространство такого вида называют \emph{симметрической схемой Бернулли}.
    \end{remark}
    Но данная модель является классической только тогда, когда монетки ``честные'', то есть которые падают орлом или решкой вверх равновероятно. Если же это не так, то вероятность элементарного исхода \(\omega = (\omega_1, \omega_2, \ldots, \omega_n)\) задаётся следующей формулой: \(\Pr(\omega) = p^{\,\sum\limits_{i = 1}^{n} \omega_i}(1 - p)^{n - \sum\limits_{i = 1}^{n} \omega_i}\).
    
    \item Урновые схемы (размещение частиц по ячейкам). Пусть есть \(n\) различных шаров в ящике. Мы случайным образом вынимаем \(m\) шаров. Вопрос: каков размер множества элементарных исходов? Сначала приведём ответ, после чего докажем его.
    \begin{center}
        \begin{tabular}{|c|c|c|c|}
            \hline \diaghead{Порядоквозврат}{Возврат?}{Порядок?} & Упорядоченный набор & Неупорядоченный набор \\
            \hline&&\\[-10pt]
            С возвратом & \(n^{m}\) & \(C_{n + m - 1}^{m} = \dfrac{(n + m - 1)!}{m!(n - 1)!}\) \\[10pt]
            \hline&&\\[-10pt]
            Без возврата & \(A_{n}^{m} = \dfrac{n!}{(n - m)!}\) & \(C_{n}^{m} = \dfrac{n!}{m!(n - m)!}\) \\[10pt]
            \hline
        \end{tabular}
    \end{center}
    \begin{proof}
        Будем доказывать утверждения от верхнего левого против часовой стрелки.
        \begin{enumerate}
            \item Пусть набор упорядочен и можно возвращать. Тогда любой элемент набора можно получить \(n\) способами (так как все элементы можно вернуть). Отсюда получаем \(n^m\).
            \item Теперь положим, что набор упорядочен, но возвращать нельзя. Тогда первый элемент можно выбрать \(n\) способами, второй~--- \(n - 1\) способом и так далее до \(m\)-го элемента, который можно выбрать \(n - m + 1\) способом. По правилу умножения получаем \(\frac{n!}{(n - m)!} = A_{n}^{m}\).
            \item Рассмотрим случай, когда набор неупорядочен и возвращать нельзя. Тогда необходимо посчитать количество способов выбрать \(k\) шаров из \(m\). Достаточно логично, что это равно \(\frac{A_{n}^{m}}{m!} = \frac{n!}{m!(n - m)!} = C_{n}^{m}\), так как в последовательности нам не важен порядок.
            \item Осталось рассмотреть последний случай~--- неупорядоченный набор с возвратом. В этом случае нам достаточно указать, сколько раз мы выбрали каждый шар. Как это сделать? Воспользуемся методом точек и перегородок. Пусть есть \(m\) точек и нужно распределить их по \(n\) группам. Для этого нужно использовать \(n - 1\) перегородку. Тогда задача сводится к нахождению количества способов выбрать \(m\) элементов из \(n + m - 1\). А это равно \(C_{n + m - 1}^{m} = \frac{(n + m - 1)!}{m!(n - 1)!}\).
        \end{enumerate}
    \end{proof}
\end{enumerate}

\subsection{Условная вероятность. Формула полной вероятности}
Пусть \((\Omega, \Pr)\)~--- дискретное вероятностное пространство.
\begin{definition}
    Пусть \(A \subseteq \Omega\)~--- некоторое событие и \(B \subseteq \Omega\)~--- другое событие, причём \(\Pr(B) > 0\). Тогда \emph{условной вероятностью события \(A\) при условии \(B\)} называют \[\Pr(A \mid B) = \dfrac{\Pr(A \cap B)}{\Pr(B)}.\]
    Если \(\Pr(B) = 0\), то положим, что \(\Pr(A \mid B) = 0\) для любого события \(A \subseteq \Omega\).
\end{definition}
Условную вероятность можно воспринимать следующим образом: сузим множество элементарных исходов до \(B\) и посчитаем вероятность события \(A\) на полученном множестве.
\begin{remark}
    Если \(\Pr(B) > 0\), то \(\tilde{\Pr}(A) = \Pr(A \mid B)\) тоже является вероятностью на \(\Omega\).
\end{remark}
\begin{definition}
    Пусть \(B_1, B_2, \ldots, B_n\)~--- некоторые события на \(\Omega\) такие, что \(\bigsqcup\limits_{i = 1}^{n} B_i = \Omega\). Тогда этот набор событий называется (конечным) \emph{разбиением} \(\Omega\).
\end{definition}
Теперь докажем важную формулу:
\begin{law-of-total-probability}
    Пусть \(B_1, B_2, \ldots, B_n\)~--- разбиение \(\Omega\). Тогда для любого события \(A \subseteq \Omega\) верно, что \(\Pr(A) = \sum\limits_{i = 1}^{n} \Pr(A \mid B_i)\Pr(B_i).\)
\end{law-of-total-probability}
\begin{proof}
    Так как \(A \cap \Omega = A\) и \(\bigsqcup\limits_{i = 1}^{n} B_i = \Omega\), то \(\Pr(A) = \Pr\left(A \cap \left(\bigsqcup\limits_{i = 1}^{n} B_i\right)\right)\). Заметим, что \(A \cap \left(\bigsqcup\limits_{i = 1}^{n} B_i\right) = \bigsqcup\limits_{i = 1}^{n} (A \cap B_i)\). Тогда
    \(\Pr(A) = \sum\limits_{i = 1}^{n} \Pr(A \cap B_i) = \sum\limits_{i = 1}^{n} \Pr(A \mid B_i)\Pr(B_i)\).
\end{proof}
Заметим, что формула полной вероятности работает и в случае, когда \(\Pr(B_i) = 0\) для какого-то \(i\).
