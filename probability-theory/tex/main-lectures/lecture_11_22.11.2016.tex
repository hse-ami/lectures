\section{Лекция от 22.11.2016}
\subsection{Классификация случайных величин. Формулы подсчёта математического ожидания}
На предыдущих лекциях мы ввели понятие математического ожидания. Но мы пока что не знаем, как его считать. Разберёмся с этим.

Перед этим введём пару важных определений:
\begin{definition}
	Пусть \(\xi\)~--- случайная величина на вероятностном пространстве \((\Omega, \mathcal{F}, \Pr)\). Тогда \emph{функцией распределения} случайной величины \(\xi\) называют функцию \(F_{\xi} : \R \to [0, 1]\), определяемую следующим образом:
	\[
	F_{\xi}(x) = \Pr{\xi \leq x}.
	\]
\end{definition}
\begin{definition}
	Пусть \(\xi\)~--- случайная величина на вероятностном пространстве \((\Omega, \mathcal{F}, \Pr)\). Тогда \emph{распределением} случайной величины \(\xi\) называется вероятностная мера \(\Pr_{\xi}\) на \((\R, \mathcal{B}(\R))\) такая, что для любого \(B \in \mathcal{B}(\R)\)
	\[
	\Pr_{\xi}(B) = \Pr{\xi \in B}.
	\]
\end{definition}
\begin{remark}
	\(\Pr_{\xi}\) действительно является вероятностной мерой, а \(F_{\xi}\) действительно является функцией распределения.
\end{remark}

Теперь введём следующую класификацию случайных величин по типу функции распределения:
\begin{enumerate}
	\item Если \(F_{\xi}\) дискретна, то будем называть случайную величину \(\xi\) \emph{дискретной}.
	
	\item Если \(F_{\xi}\) абсолютно непрерывна, то будем называть случайную величину \(\xi\) \emph{абсолютно непрерывной}. В данном случае можно ввести понятие \emph{плотности распределения}:
	\begin{definition}
		Пусть \(\xi\)~--- асболютно непрерывная случайная величина, и существует неотрицательная функция \(p_{\xi}(x)\) такая, что для любого \(x \in \R\) выполнено, что
		\[
		F_{\xi}(x) = \Pr{\xi \leq x} = \int\limits_{-\infty}^{x}p_{\xi}(t)\,\mathrm{d}t.
		\]
		Тогда \(p_{\xi}(x)\) называют \emph{плотностью распределения} случайной величины \(\xi\).
	\end{definition}

	\item Если же \(F_{\xi}(x)\) сингулярна, то \(\xi\) называют \emph{сингулярной}.
\end{enumerate}

Начнём разбираться с математическим ожиданием с дискретных случайных величин. Вообще, если \(\xi\) дискретна, то множество значений \(X = \xi(\Omega)\) не более, чем счётно, причем \(\Pr_{\xi}(X) = 1\).
\begin{theorem}
	Пусть \(\xi\)~--- дискретная случайная величина, а \(f(x)\)~--- некоторая борелевская функция, определённая на множестве значений \(X\). Тогда
	\[
	\E{f(\xi)} = \sum\limits_{x \in X} f(x)\Pr{\xi = x}.
	\]
\end{theorem}
\begin{proof}
	Для начала предположим, что \(X\) конечно. Но в этом случае \(\xi\)~--- это простая случайная величина. Следовательно, \(f(\xi)\)~--- это тоже простая случайная величина. Тогда по определению математического ожидания для простой величины:
	\begin{align}
		\E{f(\xi)} &= \sum\limits_{z \in f(X)} f(z)\Pr{f(\xi) = z} = \sum\limits_{z \in f(X)}\left(\sum\limits_{\substack{x \in X \\ f(x) = z}} z\Pr{\xi = x}\right) \\
		&= \sum\limits_{z \in f(X)}\left(\sum\limits_{\substack{x \in X \\ f(x) = z}} f(x)\Pr{\xi = x}\right) = \sum\limits_{x \in X} f(x)\Pr{\xi = x}.
	\end{align}
	
	Теперь рассмотрим случай счётного \(X\). Каким-либо образом занумеруем элементы \(X\): \(X = \{x_n\}_{n = 1}^{\infty}\).
	
	Предположим, что \(f(x)\) неотрицательна. Тогда введём последовательность случайных величин \(\{\eta_n\}_{n = 1}^{\infty}\), устроенную следующим образом:
	\[
	\eta_n = \sum_{i = 1}^{n} f(x_i)I\{\xi = x_i\}.
	\]
	
	Тогда \(\eta_n \uparrow f(\xi)\). Следовательно, \(\E{\eta_n}\) монотонно возрастает и сходится к \(\E{f(\xi)}\). Однако, в силу линейности математического ожидания простой случайной величины получаем, что
	\begin{align}
		\E{f(\xi)} &= \lim\limits_{n \to \infty} \E{\eta_n} = \lim\limits_{n \to \infty} \left(\sum_{i = 1}^{n} f(x_i)\E{I\{\xi = x_i\}}\right) \\
		&= \lim\limits_{n \to \infty} \left(\sum_{i = 1}^{n} f(x_i)\Pr{\xi = x_i}\right) = \sum_{i = 1}^{\infty} f(x)\Pr{\xi = x_i}.
	\end{align}
	
	В общем случае же представим \(f(x)\) в виде \(f^{+}(x) - f^{-}(x)\) и пользуемся доказанным ранее.
\end{proof}

Теперь приступим к абсолютно непрерывным случайным величинам.
\begin{theorem}
	Пусть \(\xi\)~--- абсолютно непрерывная случайная величина с плотностью \(p_{\xi}(x)\). Тогда
	\[
	\E{\xi} = \int\limits_{-\infty}^{+\infty} xp_{\xi}(x)\,\mathrm{d}x.
	\]
\end{theorem}
\begin{proof}
	Для начала рассмотрим неотрицательную случайнуй величину \(\xi\). Введём последовательность простых случайных величин \(\{\xi_n\}_{n = 1}^{\infty}\), устроенную следующим образом:
	\[
	\xi_n = \sum\limits_{k = 1}^{n \cdot 2^n} \frac{k - 1}{2^n}\mathop{I}\left\{\frac{k - 1}{2^n} < \xi \leq \frac{k}{2^n}\right\}.
	\]
	
	Заметим, что данная последовательность будет сходиться к \(\xi\) снизу: \(\xi_n \uparrow \xi\). Однако
	\begin{align}
		\E{\xi_n} &= \sum\limits_{k = 1}^{n \cdot 2^n} \frac{k - 1}{2^n}\Pr{\frac{k - 1}{2^n} < \xi \leq \frac{k}{2^n}} \\
		&= \sum\limits_{k = 1}^{n \cdot 2^n} \frac{k - 1}{2^n}\left(F_{\xi}\left(\frac{k}{2^n}\right) - F_{\xi}\left(\frac{k - 1}{2^n}\right)\right) = \sum\limits_{k = 1}^{n \cdot 2^n} \frac{k - 1}{2^n}\int\limits_{\frac{k - 1}{2^n}}^{\frac{k}{2^n}} p_{\xi}(x)\,\mathrm{d}x
	\end{align}
	Далее заметим, что
	\[
	\int\limits_{\frac{k - 1}{2^n}}^{\frac{k}{2^n}} \left(x - \frac{1}{2^n}\right) p_{\xi}(x)\,\mathrm{d}x \leq \frac{k - 1}{2^n}\int\limits_{\frac{k - 1}{2^n}}^{\frac{k}{2^n}} p_{\xi}(x)\,\mathrm{d}x \leq \int\limits_{\frac{k - 1}{2^n}}^{\frac{k}{2^n}} xp_{\xi}(x)\,\mathrm{d}x.
	\]
	
	Тогда, суммируя все такие элементы и вынося константу в ограничени снизу, получаем, что
	\[
	\int\limits_{0}^{n} xp_{\xi}(x)\,\mathrm{d}x - \frac{1}{2^n} \leq \int\limits_{0}^{n} \left(x - \frac{1}{2^n}\right) p_{\xi}(x)\,\mathrm{d}x \leq \E{\xi_n} \leq \int\limits_{0}^{n} xp_{\xi}(x)\,\mathrm{d}x \leq \int\limits_{0}^{\infty} xp_{\xi}(x)\,\mathrm{d}x.
	\]
	
	Отсюда получаем, что 
	\[
	\E{\xi} = \int\limits_{0}^{\infty} xp_{\xi}(x)\,\mathrm{d}x.
	\]
	
	Если же случайная величина \(\xi\) неположительна, то аналогичными рассуждениями получаем, что
	\[
	\E{\xi} = \int\limits_{-\infty}^{0} xp_{\xi}(x)\,\mathrm{d}x.
	\]
	
	В общем случае представим \(\xi\) в виде суммы неотрицательной и неположительной случайных величин. Тогда получим желаемое.
\end{proof}

Хорошо, мы научились считать матожидание абсолютно непрерывной случайной величины. Но хотелось бы научиться считать матожидание от функции от случайной величины. Следующая теорема говорит нам, как его вычислять.
\begin{theorem}
	Пусть \(\xi\)~--- абсолютно непрерывная случайная величина с плотностью \(p(x)\) и \(f(x)\)~--- некоторая борелевская функция. Тогда
	\[
	\E{f(x)} = \int\limits_{-\infty}^{+\infty} f(x)p_{\xi}(x)\,\mathrm{d}x.
	\]
\end{theorem}
\begin{proof}[Набросок доказательства]
	В случае монотонной функции \(f(x)\) рассуждение работает. Теперь предположим более слабое условие~--- неотрицательность \(f(x)\). Опять же, построим последовательность простых случайных величин \(\{\eta_n\}_{n = 1}^{\infty}\), устроенную следующим образом:
	\[
	\sum\limits_{k = 1}^{n \cdot 2^n} \frac{k - 1}{2^n}\mathop{I}\left\{\frac{k - 1}{2^n} < f(\xi) \leq \frac{k}{2^n}\right\}.
	\]
	
	Тогда \(\eta_n \uparrow f(\xi)\) и \(\E{\eta_n}\) монотонно сходится к \(\E{f(\xi)}\). Однако
	\[
	\E{\eta_n} = \sum\limits_{k = 1}^{n \cdot 2^n} \frac{k - 1}{2^n}\Pr{\frac{k - 1}{2^n} < f(\xi) \leq \frac{k}{2^n}} = \sum\limits_{k = 1}^{n \cdot 2^n} \frac{k - 1}{2^n}\Pr{\xi \in f^{-1}\left(\frac{k - 1}{2^n}, \frac{k}{2^n}\right]}
	\]
	
	Обозначим \(f^{-1}\left(\frac{k - 1}{2^n}, \frac{k}{2^n}\right]\) за \(B_{k, n}\). Тогда
	\[
	\E{\eta_n} = \sum\limits_{k = 1}^{n \cdot 2^n} \frac{k - 1}{2^n} \int\limits_{B_{k, n}}p_{\xi}(x)\,\mathrm{d}x.
	\]
	
	Дальше рассуждаем в стиле того, как мы доказывали формулу для \(\E{\xi}\).
\end{proof}

В принципе, для вычисления математического ожидания функции от случайной величины \(\xi\) достаточно знать её функцию распределения.
\begin{theorem}\footnote{Это вовсе не теорема, а определение математического ожидания. И здесь не интеграл Римана, а интеграл Лебега-Стильтеса. Попытки избежать теорию меры и функциональный анализ проваливаются с треском. (А.Х.)}
	Пусть \(\xi\)~--- это случайная величина на вероятностном пространстве \((\Omega, \mathcal{F}, \Pr)\) с функцией распределения \(F_{\xi}\), а \(f(x)\)~--- некая борелевская функция. Тогда математическое ожидание равно
	\[\E{f(\xi)} = \int\limits_{-\infty}^{+\infty} f(x)\,\mathrm{d}F_{\xi}(x).\]
\end{theorem}

Рассмотрим какой-нибудь пример.
\begin{definition}
	\emph{Гамма-функцией} \(\Gamma(\lambda)\) \((\lambda > 0)\) называют следующую функцию
	\[\Gamma(\lambda) = \int\limits_{0}^{+\infty} x^{\lambda - 1}e^{-x}\,\mathrm{d}x.\]
\end{definition}

У гамма-функции есть несколько простых свойств:
\begin{itemize}
	\item \(\Gamma(n) = (n - 1)!\) для любого \(n \in \N\),
	\item \(\Gamma(\lambda + 1) = \lambda\Gamma(\lambda)\) для любого \(\lambda > 0\),
	\item \(\Gamma\left(\frac{1}{2}\right) = \sqrt{\pi}\) (это не такое простое, ладно).
\end{itemize}

\begin{definition}
	Пусть \(\xi\)~--- некоторая случайная величина, про которую известно, что
	\[
	p_{\xi}(x) = \dfrac{\beta^{\alpha}x^{\alpha - 1}e^{-\beta x}}{\Gamma(\alpha)} \text{ при } x \geq 0, \alpha, \beta > 0.
	\]
	
	В таком случае говорят, что \(\xi\) подчиняется \emph{гамма-распределению} с параметрами \(\alpha\) и \(\beta\). Обозначается \(\xi \sim \mathrm{Gamma}(\alpha, \beta)\).
\end{definition}

Пусть у нас есть случайная величина \(\xi \sim \mathrm{Gamma}(\alpha, \beta)\). Найдём \(\E{\xi}\):
\[
\E{\xi} = \int\limits_{0}^{+\infty} \dfrac{\beta^{\alpha}x^{\alpha}e^{-\beta x}}{\Gamma(\alpha)}\diff x = \left\{u = x\beta, \diff x = \frac{\diff u}{\beta}\right\} = \frac{\Gamma(\alpha + 1)}{\beta\Gamma(\alpha)} = \frac{\alpha}{\beta}.
\]

\subsection{Независимость случайных величин и векторов}

\begin{definition}
	Случайные величины \(\xi_1, \xi_2, \dots, \xi_n\) называются \emph{независимыми в совокупности}, если для любых \(x_1, x_2, \dots, x_n \in \R\) 
	\[
	\Pr{\xi_1 \leq x_1, \dots, \xi_n \leq x_n} = \prod\limits_{i = 1}^{n} \Pr{\xi_i \leq x_i}.
	\] 
\end{definition}
\begin{remark}
	Если \(\xi_1. \xi_2, \dots, \xi_n\) независимы в совокупности, то любой поднабор тоже независим в совокупности.
\end{remark}

Теперь возникает вопрос: а можно ли заменить знак \(\leq\) на что-либо другое? Да.
\begin{theorem}
	Случайные величины \(\xi_1, \xi_2, \dots, \xi_n\) независимы тогда и только тогда, когда для любых множеств \(B_1, B_2, \dots, B_n \in \mathcal{B}(\R)\) выполнено, что
	\[
	\Pr{\xi_1 \in B_1, \xi_2 \in B_2, \dots, \xi_n \in B_n} = \prod\limits_{i = 1}^{n} \Pr{\xi_i \in B_i}.
	\]
\end{theorem}

Пользуясь этой <<теоремой>>, докажем один полезный факт.
\begin{lemma}
	Пусть \(\xi_1, \xi_2, \dots, \xi_n\)~--- независимые случайные величины, а \(f_1, f_2, \dots, f_n\)~--- некоторые борелевские функции. Тогда случайные величины \(f_1(\xi_1), f_2(\xi_2), \dots, f_n(\xi_n)\) тоже независимы.
\end{lemma}
\begin{proof}
	Проверим то, что выполнено определение:
	\begin{align}
		\Pr{f_1(\xi_1) \leq x_1, \dots, f_n(\xi_n) \leq x_n} = \Pr{\xi_1 \in f_{1}^{-1}(-\infty, x_1], \dots, \xi_n \in f_{n}^{-1}(-\infty, x_n]}
	\end{align}
	
	Заметим, что \(f_{i}^{-1}(-\infty, x_i] \in \mathcal{B}(\R)\). Тогда
	\[
	\Pr{\xi_1 \in f_{1}^{-1}(-\infty, x_1], \dots, \xi_n \in f_{n}^{-1}(-\infty, x_n]} = \prod\limits_{i = 1}^{n} \Pr{\xi_i \in f_{i}^{-1}(-\infty, x_i]}.
	\]
	
	Отсюда получаем, что
	\[
	\Pr{f_1(\xi_1) \leq x_1, \dots, f_n(\xi_n) \leq x_n}  = \prod\limits_{i = 1}^{n} \Pr{f_{i}(\xi_i) \leq x_i}. \qedhere
	\]
\end{proof}

\subsection{Математическое ожидание произведения независимых случайных величин}
В дискретном вероятностном пространстве было верно следующее утверждение: если случайные величины независимы, то матожидание произведения равно произведению матожиданий. Верно ли оно в общем случае? Докажем, что да.
\begin{theorem}
	Пусть случайные величины \(\xi\) и \(\eta\) независимы, а их матожидания конечны. Тогда матожидание случайной величины \(\xi\eta\) тоже конечно и
	\[
	\E{\xi\eta} = \E{\xi}\E{\eta}.
	\]
\end{theorem}
\begin{proof}
	Для начала рассмотрим случай простых случайных величин. Тогда их можно представить в следующем виде:
	\begin{align}
		\xi = \sum\limits_{i = 1}^{n} x_{i}I\{\xi = x_{i}\} \\
		\eta = \sum\limits_{j = 1}^{m} y_{j}I\{\eta = y_{j}\}
	\end{align}
	
	Теперь распишем матожидание произведения:
	\begin{align}
		\E{\xi\eta} &= \sum_{i = 1}^{n}\sum_{j = 1}^{m} x_{i}y_{j}\E{I\{\xi = x_{i}\}I\{\eta = y_{j}\}} = \sum_{i = 1}^{n}\sum_{j = 1}^{m} x_{i}y_{j}\Pr{\xi = x_{i}, \eta = y_{j}} \\
		&= \sum_{i = 1}^{n}\sum_{j = 1}^{m} x_{i}y_{j}\Pr{\xi = x_{i}}\Pr{\eta = y_{j}} = \left(\sum_{i = 1}^{n} x_{i}\Pr{\xi = x_{i}}\right)\left(\sum_{j = 1}^{m} y_{j}\Pr{\eta = y_{j}}\right) \\
		&= \E{\xi}\E{\eta}.
	\end{align}
	
	Теперь перейдём к случаю неотрицательных случайных величин. Построим последовательности случайных величин \(\{\xi_n\}_{n = 1}^{\infty}\) и \(\{\eta_n\}_{n = 1}^{\infty}\) такие, что \(\xi_n \uparrow \xi\) и \(\eta_n \uparrow \eta\). Тогда \(\xi_n\eta_n \uparrow \xi\eta\) и по определению
	\[
	\E{\xi\eta} = \lim\limits_{n \to \infty} \E{\xi_n \eta_n}.
	\]
	
	Но нужно следать так, чтобы \(\E{\xi_n \eta_n} = \E{\xi_n} \E{\eta_n}\). Для этого скажем, что \(\xi_n\) и \(\eta_n\) есть какие-то функции от \(\xi\) и \(\eta\) соответственно. Тогда  \(\xi_n\) и \(\eta_n\) независимы. Следовательно,
	\[
	\lim\limits_{n \to \infty} \E{\xi_n \eta_n} = \lim\limits_{n \to \infty} \E{\xi_n} \E{\eta_n} = \E{\xi} \E{\eta}.
	\]
	
	В общем же случае разобъём обе случайные величины следующим образом:
	\begin{align}
		\xi &= \xi^{+} - \xi^{-}, \\
		\eta &= \eta^{+} - \eta^{-}.
	\end{align}
	
	Тогда \(\xi\eta = (\xi\eta)^{+} - (\xi\eta)^{-}\), где
	\begin{align}
		(\xi\eta)^{+} &= \xi^{+}\eta^{+} + \xi^{-}\eta^{-}, \\
		(\xi\eta)^{-} &= \xi^{+}\eta^{-} + \xi^{-}\eta^{+}.
	\end{align}
	
	Заметим, что \(\xi^{\pm}\) независимо от \(\eta^{\pm}\), так как это функции от независимых случайных величин. Тогда, пользуясь формулой для неотрицательных случайных величин, получаем, что
	\begin{align}
		\E{(\xi\eta)^{+}} &= \E{\xi^{+}}\E{\eta^{+}} + \E{\xi^{-}}\E{\eta^{-}} \\
		\E{(\xi\eta)^{-}} &= \E{\xi^{+}}\E{\eta^{-}} + \E{\xi^{-}}\E{\eta^{+}} \\
		\E{\xi\eta} &= \left(\E{\xi^{+}} - \E{\xi^{-}}\right)\left(\E{\eta^{+}} - \E{\eta^{-}}\right) = \E{\xi} \E{\eta}.\qedhere
	\end{align}
\end{proof}