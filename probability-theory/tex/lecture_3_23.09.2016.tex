\section{Лекция от 23.09.2016}
\subsection{Распределение случайной величины. Примеры распределений}
Рассмотрим некоторое дискретное пространство \((\Omega, \Pr)\). Тогда случайная величина \(\xi\) на этом пространстве принимает не более, чем счетное множество значений. Пусть \(X = (x_1, x_2, \ldots, x_n, \ldots)\) --- множество значений случайной величины \(\xi\). Введём событие \(A_i = \{\omega : \xi(\omega) = x_i\}\). Его можно интерпретировать, как событие \(\{\xi\) приняло значение \(x_i\}\). Для удобства будем использовать обозначение \(A_i := \{\xi = x_i\}\). Также введем обозначение \(p_i\) для вероятности события \(A_i\): \(p_i = \Pr(A_i) = \Pr(\xi = x_i)\).

\begin{definition}
    Вместе множество значений \(X = (x_1, x_2, \ldots, x_n, \ldots)\) и набор вероятностей \((p_1, p_2, \ldots, p_n, \ldots)\) образуют то, что называется \emph{распределением случайной величины} \(\xi\).
\end{definition}
Понятно, что каждому числу \(x_i\) сопоставлено число \(p_i\). Легко заметить, что \(A_i\) образуют разбиение пространства \(\Omega\). Тогда \(\sum\limits_{i = 0}^{|X|} p_i = 1\).

Рассмотрим некоторые известные примеры распределений:
\begin{enumerate}
    \item Распределение Бернулли.
    \begin{definition}
        Случайная величина \(\xi\) имеет \emph{распределение Бернулли}, если она принимает всего два значения, 1 или 0, с заранее известными вероятностями \(p\) и \(q \equiv 1 - p\). Обозначение: \(\xi \sim \mathrm{Bern}(p)\).
    \end{definition}
    Легко понять, что \(X = \{0, 1\}\), \(\Pr(\xi = 1) = p\), \(\Pr(\xi = 0) = q\). Принято говорить, что событие \(\{\xi = 1\}\) соответствует ``успеху'', а событие \(\{\xi = 0\}\)~--- ``неудаче''. Эти названия достаточно условные, и в зависимости от конкретной задачи могут быть заменены на противоположные.
    
    \item Биномиальное распределение.
    \begin{definition}
        \emph{Биномиальное распределение} в теории вероятностей~--- распределение количества ``успехов'' \(\xi\) в последовательности из \(n\) независимых случайных экспериментов, таких, что вероятность ``успеха'' в каждом из них постоянна и равна \(p\). Обозначение: \(\xi \sim \mathrm{Bin}(n, p)\).
    \end{definition}
    Пусть \(x_1, \ldots, x_n\) --- последовательность независимых случайных величин с одинаковым распределением Бернулли с параметром \(p\). Тогда \(\xi = \sum\limits_{i = 1}^{n} x_i\). Посчитаем \(\Pr(\xi = k)\). Для этого необходимо выбрать \(k\) исходов из \(n\) и сказать, что они успешны. Тогда \(\Pr(\xi = k) = \binom{n}{k}p^k(1 - p)^{n - k}\). 
    
    \item Пуассоновское распределение. 
    \begin{definition}
        Говорят, что случайная величина \(\xi\) имеет \emph{распределение Пуассона}, если она принимает любое значение\footnote{Есть путаница, откуда считать~--- с нуля или же с единицы. Будем считать, что начинаем с единицы.} \(k \in \N\) с вероятностью \(\frac{\lambda^k}{k!}e^{-\lambda}\), где \(\lambda > 0\)~--- некоторый параметр. Обозначение: \(\xi \sim \mathrm{Pois}(\lambda)\).
    \end{definition}
    Почему оно вводится именно так? Об этом будет рассказано позднее.
    
    \item Геометрическое распределение.
    \begin{definition}
        Говорят, что случайная величина \(\xi\) имеет \emph{геометрическое распределение}, если она принимает любое значение \(k \in \N\) с вероятностью \(p(1 - p)^{k - 1}\). Обозначение: \(\xi \sim \mathrm{Geom}(p)\).
    \end{definition}
\end{enumerate}

\subsection{Независимость случайных величин}
Далее множество значений случайной величины \(\xi\) на вероятностном пространстве \((\Omega, \Pr)\) будем обозначать как \(\xi(\Omega)\).

\begin{definition}
    Пусть \(\xi\), \(\eta\)~--- случайные величины на вероятностном пространстве \((\Omega, \Pr)\). Будем говорить, что эти случайные величины \emph{независимы}, если для любых \(a \in \xi(\Omega)\), \(b \in \eta(\Omega)\) события \(\{\xi = a\}\) и \(\{\eta = b\}\) независимы.
\end{definition}
По опредлению независимых событий получаем, что
\[\Pr(\{\xi = a\} \cap \{\eta = b\}) = \Pr(\xi = a)\Pr(\eta = b).\]
\begin{remark}
    Для простоты левую часть часто обозначают за \(\Pr(\xi = a, \eta = b)\).
\end{remark}
Теперь обобщим это понятие на произвольное количество случайных величин:
\begin{definition}
    Пусть \(\xi_1, \ldots, \xi_n\) --- случайные величины на вероятностном пространстве \((\Omega, \Pr)\) и известно, что \(\xi_i\) принимает значения \((a_1^{(i)}, a_2^{(i)}, \ldots, a_n^{(i)})\). Тогда будем говорить, что случайные величины \(\xi_1, \ldots, \xi_n\) \emph{независимы (в совокупности)}, если \(\forall j_1, \ldots, j_n\) выполнено:
    \[\Pr(\xi_1 = a_1^{(i)}, \ldots, \xi_n = a_n^{(i)}) = \prod\limits_{k = 1}^{n}\Pr(\xi_k = a_{j_{k}}^{(k)}).\]
\end{definition}
\begin{exercise}
    Пусть \(A, B\) --- некоторые события над \((\Omega, \Pr)\). Показать, что \(A\) и \(B\) независимы тогда и только тогда, когда их индикаторы \(I_A\) и \(I_B\) независимы.
\end{exercise}
\begin{exercise}
    Показать, что случайные величины \(\xi_1, \ldots, \xi_n\) независимы тогда и только тогда, когда
    \[\forall \alpha_1, \alpha_2, \ldots, \alpha_n \in \R \quad \Pr(\xi_1 = \alpha_1, \ldots, \xi_n = \alpha_n) = \prod\limits_{i = 1}^{n}\Pr(\xi_i = \alpha_i)\]
\end{exercise}

\subsection{Математическое ожидание. Свойства математического ожидания}
Опять же, зафиксируем некоторое дискретное вероятностное пространство \((\Omega, \Pr)\).
\begin{definition}
    \emph{Математическим ожиданием} случайной величины \(\xi\) называют величину \(\E[\xi] = \sum\limits_{\omega \in \Omega} \xi(\omega)\Pr(\omega)\).
\end{definition}
\begin{remark}
    Если \(\Omega\) счётно, то ряд \(\sum\limits_{\omega \in \Omega} \xi(\omega)\Pr(\omega)\) должен сходиться абсолютно; иначе сумма ряда не определена однозначно, так как порядок перебора \(\omega\) не задан (см. теорему Римана о перестановке членов условно сходящегося ряда).
\end{remark}
Смысл у математического ожидания случайной величины простой~--- его можно понимать как среднее значение этой случайной величины.

Рассмотрим некоторые свойства математического ожидания.
\begin{theorem}[Простейшие свойства математического ожидания]
    Пусть \(\xi, \eta\)~--- некоторые случайные величины. Тогда выполняются следующие свойства:
    \begin{enumerate}
        \item Матожидание линейно: \(\forall a, b \in \R\ \E[a\xi + b\eta] = a\E[\xi] + b\E[\eta]\);
        \item Оно сохраняет относительный порядок: если \(\xi \leq \eta\) (то есть для любого \(\omega \in \Omega\) \(\xi(\omega) \leq \eta(\omega)\)), то \(\E[\xi] \leq \E[\eta]\);
        \item Модуль математического ожидания меньше математического ожидания модуля: \(\left|\E[\xi]\right| \leq \E\left[|\xi\right|]\);
        \item \(\E[\xi] = \sum\limits_{a \in \xi(\Omega)} a\Pr(\xi = a)\);
        \item Для любой функции \(\phi(x)\) выполняется \(\E[\phi(\xi)] = \sum\limits_{a \in \xi(\Omega)} \phi(a)\Pr(\xi = a)\);
        \item Если \(\Pr(\xi = c) = 1\) для некоторой константы \(c\), то \(\E[\xi] = c\);
        \item Если \(\xi \geq 0\), то \(\E[\xi] \geq 0\); 
        \item Если \(E[\xi] = 0\) и \(\xi \geq 0\), то \(\Pr(\xi = 0) = 1\);
        \item Если \(\xi\) и \(\eta\) независимы, то \(\E[\xi\eta] = \E[\xi]\E[\eta]\).
    \end{enumerate}
\end{theorem}
\begin{proof}
    Докажем пункты по порядку:
    \begin{enumerate}
        \item \(\E[a\xi + b\eta] = \sum\limits_{\omega \in \Omega} (a\xi+b\eta)(\omega) \Pr(\omega) =
        \sum\limits_{\omega \in \Omega} a\xi(\omega) \Pr(\omega) + \sum\limits_{\omega \in \Omega}b\eta(\omega) \Pr(\omega) = a\E[\xi] + b\E[\eta]\).
        \item \(\E[\xi] = \sum\limits_{\omega \in \Omega} \xi(\omega)\Pr(\omega) \leq \sum\limits_{\omega \in \Omega} \eta(\omega)\Pr(\omega) = \E[\eta]\).
        \item \(\E[-\left|\xi\right|] \leq \E[\xi] \leq \E[\left|\xi\right|] \implies -\E[\left|\xi\right|] \leq \E[\xi] \leq \E[\left|\xi\right|] \implies \left|\E[\xi]\right| \leq \E\left[|\xi\right|]\)
        \item
        \begin{multline*}
            \E[\xi] =
            \sum\limits_{\omega \in \Omega} \xi(\omega)\Pr(\omega) =
            \sum\limits_{a \in \xi(\Omega)}\sum\limits_{\omega\,:\,\xi(\omega) = a} \xi(\omega)\Pr(\omega) =
            \sum\limits_{a \in \xi(\Omega)} \left(a\sum\limits_{\omega\,:\,\xi(\omega) = a} \Pr(\omega)\right) = \\ =
            \sum\limits_{a \in \xi(\Omega)} a\Pr(\xi = a)
        \end{multline*}
        \item 
        \begin{multline*}
        \E[\phi(\xi)] =
        \sum\limits_{\omega \in \Omega} \phi(\xi(\omega))\Pr(\omega) =
        \sum\limits_{a \in \xi(\Omega)}\sum\limits_{\omega\,:\,\xi(\omega) = a} \phi(\xi(\omega))\Pr(\omega) = \\ =
        \sum\limits_{a \in \xi(\Omega)} \left(\phi(a)\sum\limits_{\omega\,:\,\xi(\omega) = a} \Pr(\omega)\right) = 
        \sum\limits_{a \in \xi(\Omega)} \phi(a)\Pr(\xi = a)
        \end{multline*}
        
        \item
        \begin{multline*}
            \E[\xi] = \sum\limits_{\omega \in \Omega} \xi(\omega)\Pr(\omega) = \sum\limits_{\omega : \xi(\omega) = c} \xi(\omega)\Pr(\omega) + \sum\limits_{\omega : \xi(\omega) \neq c} \xi(\omega)\Pr(\omega) = c \Pr(\xi = c) + \\ + \sum\limits_{\omega : \xi(\omega) \neq c}\xi(\omega)\cdot 0 = c.
        \end{multline*}
        
        \item \(\xi \geq 0 \implies \E[\xi] \geq \E[0] \geq 0\).
        
        \item \(\E[\xi] = \sum\limits_{\omega \in \Omega} \underbrace{\xi(\omega)}_{\geq 0}\underbrace{\Pr(\omega)}_{\geq 0} = 0 \implies \forall \omega \in \Omega\ \xi(\omega)\Pr(\omega) = 0\). Тогда если \(\xi(\omega) \neq 0\), то \(\Pr(\omega) = 0\). Тогда \(\Pr(\xi = 0) = 1\).
        
        Заметим, что если величина может быть и отрицательной, то это свойство не выполняется. Предположим, что \(\xi\) равновероятно принимает значения 1 и \(-1\). Тогда \(\E[\xi] = 0\), но \(\Pr(\xi = 0) = 0\).
        
        \item 
        \begin{multline*}
        \E[\xi\eta] =
        \sum_{\omega \in \Omega}\xi(\omega)\eta(\omega)\Pr(\omega) =
        \left\{
        \begin{aligned}
        \xi(\Omega) &= (a_1, a_2, \ldots)\\ 
        \eta(\Omega) &= (b_1, b_2, \ldots)
        \end{aligned}
        \right\} =
        \sum_{i, j}\sum_{
            \substack{
                \omega:\\
                \xi(\omega) = a_i\\
                \eta(\omega) = b_j
            }
        }\xi(\omega)\eta(\omega)\Pr(\omega) =\\=
        \sum_{i, j}a_ib_j\Pr(\xi = a_i, \eta = b_j)
        \end{multline*}
        Так как \(\xi \independent \eta\), то \(\Pr(\xi = a_i, \eta = b_j) = \Pr(\xi = a_i)\Pr(\eta = b_j)\) и сумма равна
        \begin{multline*}
        \sum_{i, j}a_ib_j\Pr(\xi = a_i)\Pr(\eta = b_j)=
        \left(\sum_{i}a_i\Pr(\xi = a_i)\right)\left(\sum_{j}b_j\Pr(\eta = b_j)\right)=
        \E[\xi]\E[\eta]
        \end{multline*}
     \end{enumerate}   
\end{proof}

Примеры использования математического ожидания:
\begin{enumerate}
    \item Посчитаем математическое ожидание индикатора события \(A\): \\ \(\E[I_A] = \sum\limits_{\omega \in \Omega} I_A(\omega)\Pr(\omega) = \sum\limits_{\omega \in A} \Pr(\omega) = \Pr(A)\).
    
    \item Если мы рассмотрим классическую модель, т.е. такую модель, где все исходы равновероятны, то \(\E[\xi] = \frac{1}{|\Omega|}\sum\limits_{\omega \in \Omega}\xi(\omega)\). Иначе говоря, математическое ожидание в классической модели равно среднему арифметическому возможных значений \(\xi\).
    
    \item Пусть $\xi \sim \mathrm{Bin}(n, p)$. Тогда
    \begin{multline*}
        \E[\xi] =
        \sum\limits_{k = 0}^{n} k\Pr(\xi = k) =
        \sum\limits_{k = 1}^{n} k\binom{n}{k}p^{k}(1 - p)^{n - k} =\\=
        \sum\limits_{k = 1}^{n} n\binom{n - 1}{k - 1}p^{k}(1 - p)^{n - k} =
        np \sum\limits_{t=0}^{n-1} \binom{n - 1}{t}p^{t}(1 - p)^{n - 1 - t}.
    \end{multline*}
\end{enumerate}

\subsection{Дисперсия. Ковариация. Их свойства}
\begin{definition}
    Пусть \(\xi\)~--- некоторая случайная величина над \((\Omega, \Pr)\). Тогда \emph{дисперсией} \(\xi\) называется \(\D[\xi] = \E[(\xi-\E[\xi])^2]\). 
\end{definition}
Дисперсию случайной величины можно понимать как среднеквадратическое отклонение этой случайной величины от её среднего значения (математического ожидания).
\begin{remark}
    Вероятность незначительного отклонения величины от математического ожидания, то есть \(\Pr(\E[\xi] - 2\sqrt{\D[\xi]} \leq \xi \leq \E[\xi] + 2\sqrt{\D[\xi]})\), всегда велика! Это нам пока не пригодится, но на будущее стоит запомнить.
\end{remark}
\begin{definition}
    Пусть \(\xi\) и \(\eta\)~--- две случайные величины. Тогда \emph{ковариацией} этих величин называется \(\cov(\xi, \eta) = \E\left[(\xi - \E[\xi])(\eta-\E[\eta])\right]\).
\end{definition}
Ковариацию стоит воспринимать как меру зависимости двух случайных величин.
\begin{definition}
    Две случайные величины \(\xi\) и \(\eta\) называют \emph{некоррелированными}, если \(\cov(\xi, \eta) = 0\).
\end{definition}
\begin{theorem}[Простейшие свойства дисперсии и ковариации]
    Пусть \(\xi\),\(\eta\) и \(\chi\)~--- некоторые случайные величины. Тогда выполняются следующие свойства:
    \begin{enumerate}
        \item Ковариация билинейна: \(\cov(\xi, a\eta + b\chi) = a\cov(\xi, \eta) + b\cov(\xi, \chi)\);
        \item \(\D[\xi] = \cov(\xi, \xi)\);
        \item Для любого \(c \in \R\) верно, что \(\D[c\xi] = c^2\D[\xi]\) и \(\D[\xi + c] = \D[\xi]\);
        \item Дисперсия неотрицательна: \(\D[\xi] \geq 0\). При этом \(\D[\xi] = 0 \iff \Pr(\xi = E[\xi]) = 1\);
        \item Если \(\xi\) и \(\eta\) некоррелированные, то \(\D[\xi + \eta] = \D[\xi] + \D[\eta]\);
        \item Связь с матожиданием: \(\D[\xi] = \E[\xi^2] - \left(\E[\xi]\right)^2\), \(\cov(\xi, \eta) = \E[\xi\eta] - \E[\xi]\E[\eta]\)
    \end{enumerate}
\end{theorem}
\begin{proof}
    Докажем все пункты по порядку:
    \begin{enumerate}
        \item По определению ковариации \(\cov(\xi, a\eta + b\chi) = \E\left[(\xi - \E[\xi])((a\eta + b\chi)-\E[a\eta + b\chi])\right]\). Распишем вторую скобку: \[(a\eta + b\chi)-\E[a\eta + b\chi] = (a\eta + b\chi) - a\E[\eta] - b\E[\chi] = a(\eta - \E[\eta]) + b(\chi - \E[\chi]).\] Тогда
        \[\begin{aligned}
        \cov(\xi, a\eta + b\chi) &= \E\left[(\xi - \E[\xi])(a(\eta - \E[\eta]) + b(\chi - \E[\chi]))\right] \\
        &= \E\left[a(\xi - \E[\xi])(\eta - \E[\eta]) + b(\xi - \E[\xi])(\chi - \E[\chi])\right] \\
        &= a\E[(\xi - \E[\xi])(\eta - \E[\eta])] + b\E[(\xi - \E[\xi])(\eta - \E[\eta])] \\
        &= a\cov(\xi, \eta) + b\cov(\xi, \chi).
        \end{aligned}\]
        
        \item \(\cov(\xi, \xi) = \E\left[(\xi - \E[\xi])(\xi - \E[\xi])\right] = \E\left[(\xi - \E[\xi])^2\right] = \D[\xi]\).
        
        \item Для произведения \(\D[c\xi] = \cov(c\xi, c\xi) = c^2\cov(\xi, \xi) = c^2\D[\xi]\). Для суммы \(\D[\xi + c] = \E[((\xi + c) - \E[\xi + c])^2] = \E[(\xi + c - \E[\xi] - c)^2] = \E[(\xi - \E[\xi])^2] = \D[\xi]\).
        
        \item По определению дисперсии, \(D[\xi] = \E[(\xi-\E[\xi])^2]\), а \((\xi-\E[\xi])^2 \geq 0\). Тогда \(\E[(\xi-\E[\xi])^2] \geq 0\).
        
        \item Воспользуемся выражением дисперсии через ковариацию и билинейностью ковариации:
        \(\D[\xi + \eta] = \cov(\xi + \eta, \xi + \eta) = \cov(\xi, \xi) + \cov(\eta, \eta) + 2\cov(\xi, \eta)\). Так как \(\xi\) и \(\eta\) некоррелированные, то \(\cov(\xi, \eta) = 0\) и \(\D[\xi + \eta] = \cov(\xi, \xi) + \cov(\eta, \eta) = \D[\xi] + \D[\eta]\).
        
        \item \(\cov(\xi, \eta) = \E\left[(\xi - \E[\xi])(\eta-\E[\eta])\right] = \E[\xi\eta - \xi\E[\eta] - \eta\E[\xi] + \E[\xi]\E[\eta]]\). По линейности матожидания \(\cov(\xi, \eta) = \E[\xi\eta] - 2\E[\xi]\E[\eta] + \E[\xi]\E[\eta] = \E[\xi\eta] - \E[\xi]\E[\eta]\). Для дисперсии воспользуемся тем, что \(\D[\xi] = \cov(\xi, \xi)\).
    \end{enumerate}
\end{proof}
\begin{theorem}
    Если случайные величины независимы, то они \emph{некоррелированные}. Обратное, вообще говоря, неверно.
\end{theorem}
\begin{proof}
    Докажем, что из независимости следует некоррелируемость. Пусть \(\xi\) и \(\eta\)~--- независимые случайные величины. Тогда \(\cov(\xi, \eta) = \E[\xi\eta] - \E[\xi]\E[\eta]\). Но по свойству матожидания из независимости случайных величин следует, что \(\E[\xi\eta] = \E[\xi]\E[\eta]\). Тогда \(\cov(\xi, \eta) = 0\) и эти величины некоррелированные.
    
    Теперь покажем, что из некоррелированности не обязательно следует независимость. Пусть случайная величина \(\xi\) равновероятно принимает значения из множества \(\{0, 1, -1\}\). Возьмем случайную величину \(\eta = \xi^2\). По определению можно проверить, что величины \(\eta\) и \(\xi\) \emph{некоррелированные}: \(\cov(\xi, \eta) = \E[\xi\eta] - \E[\xi]\E[\eta] = \E[\xi^3] - \E[\xi]\E[\xi^2] = 0 - 0 = 0\). Но \(\xi\) и \(\eta\) \emph{не являются независимыми}, что проверяется опять же по определению: \(\Pr(\xi = 0, \eta = 0) = \frac{1}{3} \neq \frac{1}{9} = \Pr(\xi = 0)\Pr(\eta = 0)\).
\end{proof}

\subsection{Неравенства Маркова и Чебышёва}
Под конец лекции обсудим два неравенства, которые сами по себе являются весьма полезными.
\begin{theorem}[Неравенство Маркова]
    Пусть \(\xi \geq 0\)~--- неотрицательная случайная величина на \((\Omega, \Pr)\). Тогда для любого положительного \(a\) \[\Pr(\xi \geq a) \leq \dfrac{\E[\xi]}{a}.\]
\end{theorem}
\begin{proof}
    Как было доказано ранее, матожидание индикатора события равно вероятности события. Тогда \(\Pr(\xi \geq a) = \E[I_{\xi \geq a}]\). Далее, заметим, что \(I_{\xi \geq a} \leq \frac{\xi}{a}I_{\xi \geq a}\). Тогда \[\Pr(\xi \geq a) \leq \E\left[\frac{\xi}{a}I_{\xi \geq a}\right] \leq \E\left[\frac{\xi}{a}\right] = \frac{\E[\xi]}{a}.\qedhere\]
\end{proof}
\begin{theorem}[Неравенство Чебышёва]
    Пусть \(\xi\)~--- случайная величина на \((\Omega, \Pr)\) такая, что \(\D[\xi] < \infty\). Тогда для любого положительного \(a\) \[\Pr\left(|\xi - E[\xi]| \geq a\right) \leq \frac{\D[\xi]}{a^2}.\]
\end{theorem}
\begin{proof}
    \(\Pr(|\xi - \E[\xi]| \geq a) = \Pr\left((\xi - E[\xi])^2 \geq a^2\right)\). По неравенству Маркова
    \[\Pr\left((\xi - E[\xi])^2 \geq a^2\right) \leq \frac{\E[(\xi - E[\xi])^2]}{a^2} = \frac{\D[\xi]}{a^2}.\qedhere\]
\end{proof}