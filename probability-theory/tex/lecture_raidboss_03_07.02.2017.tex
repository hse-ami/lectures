\section{Лекция от 07.02.2017}

\subsection{Среднее время в нуле}

Вспомним, что по ЦПТ и тем фактом, что среднее $\xi_i$ равно нулю и дисперсия равна 
единице мы имеем следующее:

\[
  \frac{S_n}{\sqrt{n}} \dto \mathcal{N}(0, 1)
\]

По теореме о наследовании сходимости можно заключить, что

\[
  \frac{|S_n|}{\sqrt{n}} \dto |\mathcal{N}(0, 1)|
\]

А теперь мы хотим осознать, а как ведет себя среднее левой части. Заметим, что
просто матожидание мы не можем взять, так как функция $f(x) = x$ не ограничена
и эквивалентным определением сходимости по распределению напрямую воспользоваться
нельзя. Поэтому нужны более сильные знания о поведений случайных величин.

\begin{definition}
  Последовательность $\{\xi_n, n \in \N\}$ называется равномерно интегрируемой,
  если

  \[
    \lim\limits_{c \to +\infty} \sup\limits_{n \in \N} \E{|\xi_n|I\{|\xi_n| \geq c\}} = 0
  \]
\end{definition}

Поясним определение.

Если у случайной величины есть плотность, то фактически мы говорим, что

\[
  \sup\limits_{n \in \N} \int\limits_{|x| \geq c} |x| p_{\xi_n}(x) dx \to 0
\]

То есть модуль среднего на бесконечности в обе стороны близок к нулю.

\begin{theorem}
  Пусть $\xi_n \dto \xi, \xi_n \geq 0$ --- все величины с конечным матожиданием,
  тогда $\E{\xi_n} \to \E{\xi}$ тогда
  и только тогда, когда последовательность $\{\xi_n, n \in \N\}$ равномерно 
  интегрируема.
\end{theorem}

\begin{proof}
  Докажем в одну сторону, в другую оставим в качестве домашней задачи.

  Пусть последовательность равномерно интегрируема. Тогда для $c > 0$ рассмотрим
  функцию $f_c(x)$:

  \begin{center}
    \begin{tikzpicture}
    
    \draw[very thick,->] (-3,0) -- (10,0) node[anchor=north, below left] {$x$};
    \draw[very thick,->] (0,0) -- (0, 7) node[anchor=east] {$f_c(x)$};

    \node [below] at (0, 0) {$0$};
    \node [below] at (5, 0) {$c$};
    \node [below] at (6, 0) {$c + 1$};
    \node [above left] at (4, 4) {$x = f_c(x)$};


    \draw[very thick, -, blue] (-3, 0) -- (0, 0);
    \draw[very thick, -, blue] (-3, 0) -- (0, 0);
    \draw[very thick, -, blue] (0, 0) -- (5, 5);
    \draw[very thick, -, blue] (5, 5) -- (6, 0);
    \draw[very thick, -, blue] (6, 0) -- (9, 0);
    \draw[very thick, -, dashed] (5, 5) -- (5, 0);

    \end{tikzpicture}
  \end{center}

  То есть до $0$ эта функция тождественно ноль, потом ведет себя так же, как
  и аргумент до $c$, потом резко убывает и снова становится нулем. Мы вводим
  такую функцию, чтобы приблизить $f(x) = x$, но ограниченным образом.

  Заметим, что $f_c(x)$ непрерывна и ограничена. Оценим $|\E{\xi_n} - \E{\xi}|$.
  Добавим и вычтем каждое из двух выражений под модулем $\E{f_c(\xi_n)}, \E{f_c(\xi)}$
  и воспользуемся неравенством треугольника:

  \[
    |\E{\xi_n} - \E{\xi}| \leq |\E{\xi_n} - \E{f_c(\xi_n)}| + 
    |\E{\xi} - \E{f_c(\xi)}| + |\E{f_c(\xi_n)} - \E{f_c(\xi)}|
  \]

  Зафиксируем произвольное $\epsilon > 0$. Первое слагаемое не больше 
  $\E{\xi_n I\{\xi_n \geq c\}}$, так как при $\xi_n \leq c$, величины просто
  совпадают, от $c$ до $c + 1$ будет какой-то остаток, не больший, чем $\E{\xi_n 
  I\{c \leq \xi_n \leq c + 1\}}$, а дальше уже просто $\E{f_c(\xi_n)}$ не даёт
  никакого вклада. Откуда $\E{\xi_n I\{\xi_n \geq c\}} \leq \frac{\epsilon}{2}$
  при всех $c > c_0(\epsilon)$. Эта оценка работает по условию теоремы при всех $n$.

  Второе слагаемое для всех $c > c_1(\epsilon)$ тоже не больше, чем $\frac{\epsilon}{2}$,
  так как мы приближаем $f_c(x)$ положительную функцию (и при $c \to +\infty$ $f_c(x) \to x$)
  и матожидание конечно, то с какого-то момента разность станет очень маленькой.

  Третье слагаемое стремится к нулю с ростом $n$ из-за эквивалентного определения
  сходимости по распределению.

  Поэтому получаем, что

  \[
    \forall \epsilon > 0 \varlimsup\limits_{n \to +\infty} |\E{\xi_n} - \E{\xi}| \leq \epsilon
  \]

  Откуда есть предел и равен он нулю, что и требовалось доказать.
\end{proof}


Но теперь, чтобы наконец-то понять асимптотику среднего в нуле, давайте
поймём, какие условия <<полегче>> нужно наложить, чтобы последовательность
была равномерно интегрируемой. Это можно сделать из следующей леммы:

\begin{lemma}
  Пусть $\{\xi_n, n \in \N\}$ --- последовательность случайных величин. Если
  для всех $n \in \N$ выполнено, что $\E{\xi_n^2} \leq C < +\infty$, тогда
  последовательность равномерно интегрируема.
\end{lemma}

\begin{proof}
  Для любого $\epsilon > 0$ выберем $t_0$ такое, что $t_0 > \frac{C}{\epsilon}$.
  Тогда для любого $t > t_0$ и любого $n \in \N$

  \[
    \E{|\xi_n|I\{|\xi_n| \geq t\}} \leq \E{\frac{\xi_n^2}{t}I\{|\xi_n| \geq t\}}
    \leq \frac{C}{t} \leq \frac{C}{t_0} < \epsilon
  \]

  Значит предел есть и равен нулю.
\end{proof}

Теперь сформулируем основную теорему:

\begin{theorem}
  \[
    \E{L_n} \sim \sqrt{\frac{2n}{\pi}}
  \]
\end{theorem}

\begin{proof}
  По последней лемме из прошлой лекции имеем $\E{L_n} = \E{|S_{n + 1}|}$.

  А также мы выяснили, что

  \[
    \frac{|S_n|}{\sqrt{n}} \dto |\mathcal{N}(0, 1)|
  \]

  Посмотрим на второй момент левой части и вспомним, что среднее у $S_n$ равно
  нулю:

  \[
    \E{\frac{S_n^2}{n}} = \frac{\D{S_n}}{n} = 1
  \]

  Последнее равенство следует из того, что дисперсия независимых величин равна
  сумме дисперсий.

  Получаем, что второй момент всегда ограничен единицей, значит по теореме 5
  мы получаем, что

  \[
    \E{\frac{|S_n|}{\sqrt{n}}} \to \E{|\mathcal{N}(0, 1)|} = \sqrt{\frac{2}{\pi}}
  \]

  Где последнее равенство легко проверяется интегрированием (см одно из ДЗ обычного
  курса).

  Получаем, что $\E{L_n} \sim \sqrt{\dfrac{2n}{\pi}}$
\end{proof}

\subsection{Геометрия траекторий. Закон повторного логарифма}

Начнём сразу с теоремы, потом будем пояснять её смысл и постепенно доказывать.

\begin{theorem}[Закон повторного логарифма]
  Пусть $\{S_n, n \in \Z_+\}$ --- простое симметричное случайное блуждание.

  Тогда 

  \[
    \Pr{\varlimsup\limits_{n \to +\infty} \frac{S_n}{\sqrt{2n\ln\ln n}} = 1} = 1
  \]
\end{theorem}

Выведем маленькое следствие из этого:

\begin{remark}
  Докажем, что из ЗПЛ следует следующий факт:

  \[
    \Pr{\varliminf\limits_{n \to +\infty} \frac{S_n}{\sqrt{2n\ln\ln n}} = -1} = 1
  \]

  Ну это легко понять, если заменить $S_n = -X_n$ и надо лишь осознать, что 
  $\{X_n, n \in \Z_+\}$
  тоже случайное блуждание, но это совершенно ясно из определения.
\end{remark}

Давайте будем пояснять смысл.

Закон повторного логарифма занимает промежуточное положение между законом 
больших чисел и центральной предельной теоремой. Мы знаем, что

\[
  \frac{S_n}{n} \prto 0, \frac{S_n}{\sqrt{n}} \dto \mathcal{N}(0, 1)
\]

Центральная предельная теорема утверждает, что суммы $S_{n}$ с делителем
$\sqrt{n}$ сходятся к стандартному нормальному распределению, и эта
последовательность сумм не сходится к какой-либо конкретной величине ни по
вероятности, ни почти наверное, а бесконечно блуждает.

Таким образом величина $S_{n}/{\sqrt{2n\ln \ln n}}$ будет
к любой точке отрезка $[-1, 1]$ бесконечное число раз приближаться
сколь угодно близко почти наверное.

Так же ЗПЛ означает, что с вероятностью один график блуждания лежит между 
$(1 + \epsilon){\sqrt{2n\ln \ln n}}$ и $-(1 + \epsilon){\sqrt{2n\ln \ln n}}$
для любого $\epsilon > 0$ и бесконечное число раз выходит за пределы
$(1 - \epsilon){\sqrt{2n\ln \ln n}}$ и $-(1 - \epsilon){\sqrt{2n\ln \ln n}}$.

Вспомним лемму Бореля-Кантеля, а сам ЗПЛ докажем на следующей лекции.

\begin{definition}
  Пусть $\{A_n, n \in \N\}$ -- события. Тогда событием $\{A_n \text{ беск. число}\}$
  (или $\{A_n \text{ б. ч.}\}$)
  называют $\bigcap\limits_{n = 1}^{+\infty}\left(\bigcup\limits_{m \geq n} A_m\right)$. Событие
  состоит в том, что произошло бесконечное число событий.
\end{definition}

\begin{theorem}[Лемма Бореля-Кантеля]
  Пусть $\{A_n, n \in \N\}$. 

  1) Если $\sum\limits_{n = 1}^{+\infty} \Pr{A_n}$ сходится,
  тогда $\Pr{\{A_n \text{ б. ч.}\}} = 0$.

  2) Если $\sum\limits_{n = 1}^{+\infty} \Pr{A_n}$ расходится и $A_n$ независимые
  величины,
  тогда $\Pr{\{A_n \text{ б. ч.}\}} = 1$.
\end{theorem}

\begin{proof}
  1)

  \[
    \Pr{\{A_n \text{ б. ч.}\}} = \Pr{\bigcap\limits_{n = 1}^{+\infty}\left(\bigcup\limits_{m \geq n} A_m\right)} =
    \lim\limits_{n \to +\infty} \Pr{\bigcup\limits_{m \geq n} A_m} \leq
    \lim\limits_{n \to +\infty} \sum\limits_{m \geq n} \Pr{A_m} = 0
  \]

  Последнее равенство верно, так как остаток сходящего ряда стремится к нулю.

  2) Тут уже напрямую не получится, надо провести более тонкий анализ:

  \[
     \Pr{\{A_n \text{ б. ч.}\}} =  \lim\limits_{n \to +\infty} \Pr{\bigcup\limits_{m \geq n} A_m} = 1 - \lim\limits_{n \to +\infty} \Pr{\bigcap\limits_{m \geq n} \overline{A_m}} = 
  \]

  Хочется воспользоваться независимостью, но в данном случае надо применять один
  трюк, чтобы это стало возможным. Поставим повторный предел:

  \[
    =  1 - \lim\limits_{n \to +\infty}\lim\limits_{N \to +\infty} \Pr{\bigcap\limits_{m = n}^{N} \overline{A_m}} = 
  \]

  Вот теперь уже можно пользоваться независимостью событий (а значит и их
  дополнений).

  \[
    1 - \lim\limits_{n \to +\infty}\lim\limits_{N \to +\infty} \prod_{m = n}^{N}(1 -
    \Pr{A_m}) 
  \]

  Применим неравенство, что $1 - x \leqslant e^{-x}$ и поэтому можно написать, что

  \[
    1 - \lim\limits_{n \to +\infty}\lim\limits_{N \to +\infty} \prod_{m = n}^{N}(1 -
    \Pr{A_m}) \geq 1 - \lim\limits_{n \to +\infty}\lim\limits_{N \to +\infty}
    e^{-\sum\limits_{m = n}^{N} \Pr{A_m}}
  \]

  Но остаток расходящегося ряда стремится к $+\infty$, поэтому имеем равенство

  \[
    = 1 - \lim\limits_{n \to +\infty}e^{-\infty} = 1
  \]
\end{proof}
