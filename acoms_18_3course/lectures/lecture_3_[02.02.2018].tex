\section{Лекция 3}
\subsection{Оценки максимального правдоподобия}
Сегодня мы будем обсуждать то, что преобразило статистику "--- метод максимального правдоподобия. Начнём с того, что введём понятие правдоподобия.
\begin{definition}
    Пусть $\vec{X} = (X_{1}, \ldots, X_{n})$ "--- наблюдение с неизвестным распределением $\Pr \in \{\Pr_{\theta}, \theta \in \Theta\}$, где $\{\Pr_{\theta}, \theta \in \Theta\}$ есть доминируемое семейство с плотностью $p_{\theta}(\vec{x})$.\footnote{Плотность понимается в обобщённом смысле "--- за подробностями обращайтесь ко второй лекции.} Тогда \emph{функцией правдоподобия} называется случайная величина $f_{\theta}(\vec{X}) = p_{\theta}(\vec{X})$.
\end{definition}
\begin{remark}
    Если $\vec{X} = (X_{1}, \ldots, X_{n})$ "--- выборка, то плотность случайного вектора разбивается в произведение плотностей координат:
    \[
        f_{\theta}(\vec{X}) = p_{\theta}(\vec{X}) = \prod_{i = 1}^{n} p_{\theta}(X_{i}).
    \]
\end{remark}
Теперь можно ввести и сам метод.
\begin{definition}
    Оценкой параметра $\theta$ по методу максимального правдоподобия, или же \emph{оценкой максимального правдоподобия}, называется
    \[
        \hat{\theta}(\vec{X}) = \arg\max_{\theta \in \Theta} f_{\theta}(\vec{X}).
    \]
\end{definition}
Данное определение уже накладывает несколько ограничений: как минимум, то, что максимум существует и он единственен. Но в дальнейшем будем считать, что они выполнены. Философия этого метода уже не так очевидна. Она состоит в том, что <<мы живём в наиболее вероятном мире>>.

Допустим, что мы рассматриваем схему Бернулли и у нас выпало много нулей и мало единиц. Мы думаем: <<Наверное, это неспроста!>> Тогда, наверное, так и должно быть на самом деле "--- действительно, в дискретном случае функция правдоподобия есть вероятность того, что выпадает данный набор. Далее, мы подбираем $\theta$ такое, что данный набор наблюдений наиболее вероятен "--- коли уж он выпал, то истинным значением должно быть только то, в котором он выпадает с наибольшей вероятностью.

Рассмотрим пару примеров нахождения оценки максимального правдоподобия, для того, чтобы понять, что вообще происходит.
\begin{problem}
    Пусть $\vec{X} = (X_{1}, \ldots, X_{n})$ "--- выборка из равномерного распределения $\mathrm{U}(0, \theta)$, $\theta > 0$. Найти оценку максимального правдоподобия параметра $\theta$.
\end{problem}
\begin{proof}[Решение]
    Начнём с того, что распишем функцию правдоподобия:
    \[
        f_{\theta}(\vec{X}) = \prod_{i = 1}^{n} p_{\theta}(X_{i}) = \prod_{i = 1}^{n} \frac{1}{\theta}[0 \leq X_{i} \leq \theta] = \frac{1}{\theta^{n}}[0 \leq X_{(1)} \leq X_{(n)} \leq \theta].
    \]
    Теперь нам нужно максимизировать её, как функцию от $\theta$. Заметим, что $\theta^{-n}$ есть монотонно убывающая функция, поэтому нужно взять минимальное $\theta$ такое, что функция правдоподобия не обратится в ноль. Но тогда $\hat{\theta}(\vec{X}) = X_{(n)}$.
\end{proof}

\begin{problem}
    Пусть $\vec{X} = (X_{1}, \ldots, X_{n})$ "--- выборка из нормального распределения $\mathcal{N}(\mu, \sigma^{2})$. Найдите оценку максимального правдоподобия параметра $\vec{\theta} = (\mu, \sigma^{2})$.
\end{problem}
\begin{proof}[Решение]
    Опять же, начнём с того, что распишем функцию правдоподобия:
    \[
        f_{\vec{\theta}}(\vec{X}) 
        = \prod_{i = 1}^{n} p_{\vec{\theta}}(X_{i}) 
        = \prod_{i = 1}^{n} \frac{1}{\sqrt{2\pi\sigma^{2}}}\exp\left\{-\frac{(X_{i} - \mu)^{2}}{2\sigma^{2}}\right\}
        = \left(\frac{1}{\sqrt{2\pi\sigma^{2}}}\right)^{n} \exp\left\{-\frac{1}{2\sigma^{2}} \sum_{i = 1}^{n} (X_{i} - \mu)^{2}\right\}.
    \]
    
    Нам нужно максимизировать её одновременно по $\mu$ и по $\theta$. Но работать с экспонентой достаточно неудобно, поэтому прологарифмируем её. Это не поменяет решения, так как логарифм биективно переводит $\mathbb{R}_{++}$ в $\mathbb{R}$:
    \[
        \ln f_{\vec{\theta}}(\vec{X})
        = -\frac{n}{2}\ln 2\pi - \frac{n}{2}\ln \sigma^{2} - \frac{1}{2\sigma^{2}} \sum_{i = 1}^{n} (X_{i} - \mu)^{2}.
    \]
    Эта функция дифференцируема, поэтому можно достаточно легко найти всех претендентов на точки экстремума прирваниваем производной к нулю:
    \begin{align*}
        0 = \pdv{\mu} \ln f_{\vec{\theta}}(\vec{X})
        &= \frac{1}{\sigma^{2}}\sum_{i = 1}^{n} (X_{i} - \mu), \\
        0 = \pdv{\sigma^{2}} \ln f_{\vec{\theta}}(\vec{X})
        &= -\frac{n}{2\sigma^{2}} + \frac{1}{2\sigma^{4}}\sum_{i = 1}^{n} (X_{i} - \mu)^{2}.
    \end{align*}
    Отсюда несложно получить, что претендентами на точки экстремума будут 
    \begin{align*}
        \hat{\mu}(\vec{X}) 
        &= \frac{1}{n}\sum_{i = 1}^{n} X_{i} = \overline{\vec{X}}, \\
        \hat{\sigma}^{2}(\vec{X})
        &= \frac{1}{n}\sum_{i = 1}^{n} \left(X_{i} - \frac{1}{n}\sum_{i = 1}^{n} X_{i}\right)^{2} = S^{2}.
    \end{align*}
    Но данная точка действительно будет являться максимумом, что несложно проверить по значениям производных. Так как она есть единственный максимум, то это глобальный максимум и $\hat{\theta}(\vec{X}) = (\overline{\vec{X}}, S^{2})$.
\end{proof}
\begin{remark}
    Несложно показать, что $S^{2}$ "--- смещённая оценка. Но оценка максимального правдоподобия не обязательно несмещённая. Вообще, несмещённость "--- достаточно сильное свойство (и получить из оценки несмещённую может быть весьма нетривиально) в том плане, что мы хотим равенство матожиданий. Но у ОМП есть так называемая \emph{асимптотическая несмещённость}: предел матожиданий будет именно таким, каким и должен быть.
\end{remark}

У оценок максимального правдоподобия и функции правдоподобия есть достаточно интересные свойства. Но они требуют некоторых условий регулярности. Будем постепенно формулировать их и доказывать свойства.
\begin{enumerate}[label=(R\arabic*)]
    \item Параметрическое семейство распределений $\set{\Pr_{\theta} \mid \theta \in \Theta}$ "--- это доминируемое семейство с плотностью $p_{\theta}(x)$ и \emph{различимыми распределениями}, то есть $\Pr_{\theta_{0}} = \Pr_{\theta_{1}}$ почти везде тогда и только тогда, когда $\theta_{0} = \theta_{1}$.
    
    \item $\vec{X} = (X_{1}, \ldots, X_{n})$ "--- выборка растущего размера из неизвестного распределения $\Pr \in \set{\Pr_{\theta} \mid \theta \in \Theta}$.
    
    \item $A = \set{x \colon p_{\theta}(x) > 0}$ не зависит от $\theta$.
\end{enumerate}

\begin{theorem}[Экстремальное свойство правдоподобия]
    В условиях регулярности (R1)"--~(R3) для всех различных $\theta_{0}$, $\theta_{1} \in \Theta$
    \[
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(f_{\theta_{0}}(\vec{X}) > f_{\theta_{1}}(\vec{X})) = 1.
    \]
\end{theorem}
\begin{proof}
    Будем считать, что мы будем работаем в $A$. Посмотрим, при каких условиях выполняется событие $f_{\theta_{0}}(\vec{X}) > f_{\theta_{1}}(\vec{X})$. Для этого прологарифмируем и преобразуем выражение:
    \[
        \ln \frac{f_{\theta_{1}}(\vec{X})}{f_{\theta_{0}}(\vec{X})} < 0 \implies \frac{1}{n}\sum_{i = 1}^{n} \ln \frac{p_{\theta_{1}}(X_{i})}{p_{\theta_{0}}(X_{i})} < 0.
    \]
    По усиленному закону больших чисел
    \[
        \frac{1}{n}\sum_{i = 1}^{n} \ln \frac{p_{\theta_{1}}(X_{i})}{p_{\theta_{0}}(X_{i})} \xrightarrow{\Pr_{\theta_{0}}\text{-п.н.}} \EE_{\theta_{0}}\left[\ln \frac{p_{\theta_{1}}(X_{1})}{p_{\theta_{0}}(X_{1})}\right].
    \]
    Теперь докажем, что\footnote{Небольшое примечание: если добавить минус к этому матожиданию, то получим широко известную \emph{дивергенцию Кульбака-Лейблера}. По сути, мы доказываем то, что она неотрицательна и то, что она равна нулю тогда и только тогда, когда плотности равны почти везде.}
    \[
        \EE_{\theta_{0}}\left[\ln \frac{p_{\theta_{1}}(X_{1})}{p_{\theta_{0}}(X_{1})}\right] < 0.
    \]
    Воспользуемся неравенством Йенсена:
    \[
        \EE_{\theta_{0}}\left[\ln \frac{p_{\theta_{1}}(X_{1})}{p_{\theta_{0}}(X_{1})}\right]
        \leq \ln \EE_{\theta_{0}}\left[ \frac{p_{\theta_{1}}(X_{1})}{p_{\theta_{0}}(X_{1})} \right] 
        = \ln \int_{A} \frac{p_{\theta_{1}}(X_{1})}{p_{\theta_{0}}(X_{1})} p_{\theta_{0}}(X_{1})\mu(\dd x) = \ln \EE_{\theta_{1}}[1] = 0.
    \]
    Но почему оно не равно нулю? Предположим, что это так:
    \[
        \EE_{\theta_{0}}\left[\ln \frac{p_{\theta_{1}}(X_{1})}{p_{\theta_{0}}(X_{1})}\right] = 0.
    \]
    Но в таком случае можно воспользоваться критерием равенства для неравенства Йенсена: $\phi(\EE[\xi]) = \EE[\phi(\xi)]$ тогда и только тогда, когда $\phi$ линейна почти везде. Но $\ln(x)$ нелинейна. Тогда получаем, что аргумент должен быть равен единице почти везде: $\mu(\set{x \colon p_{\theta_{0}}(x) = p_{\theta_{1}}(x)}) = 1$. Но это означает, что $\theta_{0} = \theta_{1}$, что противоречит условию. 
    
    В итоге получаем, что
    \[
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(f_{\theta_{0}}(\vec{X}) > f_{\theta_{1}}(\vec{X})) 
        = \Pr_{\theta_{0}}\left(\EE_{\theta_{0}}\left[\ln \frac{p_{\theta_{1}}(X_{1})}{p_{\theta_{0}}(X_{1})}\right] < 0\right) = 1. \qedhere
    \]
\end{proof}
\begin{consequence}[Состоятельность оценки максимального правдоподобия]
    Если $\Theta$ конечно, что оценка максимального правдоподобия состоятельна.
\end{consequence}
\begin{proof}
    Пусть $\hat{\theta}_{n}(\vec{X})$ "--- это оценка максимального правдоподобия. Тогда по экстремальному свойству правдоподобия для любого $\theta_{0} \in \Theta$
    \[
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(\hat{\theta}_{n}(\vec{X}) = \theta_{0}) 
        = \lim\limits_{n \to \infty} \Pr_{\theta}(\forall \theta \neq \theta_{0} f_{\theta_{0}}(\vec{X}) > f_{\theta}(\vec{X}))
        = 1. \qedhere
    \]
\end{proof}

Введём ещё два условия регулярности:
\begin{enumerate}[label=(R\arabic*), start=4]
    \item $\Theta$ есть открытый интервал на $\mathbb{R}$.
    \item $p_{\theta}(x)$ непрерывно дифференцируема по $\theta$ для всех $x \in A$.
\end{enumerate}
Теперь можно доказать хорошее свойство, плотно связанное с оценками максимального правдоподобия.
\begin{theorem}[Состоятельность решения уравнения правдоподобия]
    В условиях регулярности (R1)"--~(R5) \emph{уравнение правдоподобия}
    \[
        \pdv{\theta}\ln f_{\theta}(\vec{X}) = 0
    \]
    с вероятностью, стремящейся к 1, имеет решение, которое сходится по вероятности к истинному значению параметра.
\end{theorem}
\begin{proof}
    Пусть $\theta_{0}$ есть истинное значение параметра. Возьмём $\delta > 0$ такое, что $[\theta_{0} - \delta, \theta_{0} + \delta] \subset \Theta$ (это возможно из-за открытости $\Theta$). Далее, введём следующее событие:
    \[
        A_{n} = \set{f_{\theta_{0}}(\vec{X}) > f_{\theta_{0} + \delta}(\vec{X}), f_{\theta_{0}}(\vec{X}) > f_{\theta_{0} - \delta}(\vec{X})}
    \]
    Тогда по экстремальному свойству правдоподобия
    \[
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(A_{n}) = 1.
    \]
    Что можно сказать, если выполнено $A_{n}$? Так как по (R6) производная логарифма функции правдоподобия непрерывна по $\theta$, то на отрезке $[\theta_{0} - \delta, \theta_{0} + \delta]$ будет точка, в которой возрастание заменяется убыванием. Следовательно, на нём будет хотя бы один корень уравнения правдоподобия. Допустим, что на этом отрезке есть несколько корней (не обязательно конечное число). Пусть $\tilde{\theta}(\vec{X})$ "--- ближайший к $\theta_{0}$ корень. Это возможно, так как предел корней тоже является корнем (так как производная непрерывна). Тогда оказывается, что для всех $\epsilon > 0$
    \[ 
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(|\tilde{\theta}(\vec{X}) - \theta_{0}| \leq \epsilon) 
        = 1.
    \]
    Почему это так? Зафиксируем $\epsilon$ и заметим, что рассуждения выше легальны для $\delta = \epsilon$. Следовательно, с вероятностью, стремящейся к 1, на отрезке $[\theta_{0} - \epsilon, \theta_{0} + \epsilon]$ будет корень. Но $\tilde{\theta}(\vec{X})$ "--- ближайший к $\theta_{0}$ корень. Тогда он лежит в этом отрезке.
\end{proof}
Вот доказали мы эту теорему. Но она больше напоминает решето, из которого вытекают проблемы. Почему?
\begin{enumerate}
    \item Например, корней уравнения правдоподобия может быть несколько. В доказательстве мы выбираем ближайший из них к истинному значению. Но как его выбрать?
    \item Даже если мы его найдём, то он зависит от истинного значения, то есть вообще не является оценкой.
    \item Почему $\tilde{\theta}(\vec{X})$ есть точка максимума? Мы сказали, что это корень уравнения, но он не обязательно даёт максимум "--- может оказаться, что это точка минимума или же точка перегиба (если корней несколько).
    \item Корень существует не всегда, а только с большой вероятностью.
\end{enumerate}
Впрочем, если сказать, что уравнение правдоподобия имеет только один корень, то всё достаточно неплохо. Четвёртый и второй вопросы отпадают сразу же, да и первый тоже. Остался третий, но он тоже исправляется:
\begin{theorem}
    Если для всех $\vec{X} = (X_{1}, \ldots, X_{n})$ уравнение правдоподобия имеет единственный корень $\hat{\theta}(\vec{X})$, то с вероятностью, стремящейся к 1, $\hat{\theta}(\vec{X})$ будет оценкой максимального правдоподобия и онценка максимального правдоподобия будет состоятельной.
\end{theorem}
\begin{proof}
    По сути, доказательство повторяет то, что было сказано выше. Пусть $\theta_{0}$ "--- истинное значение параметра. Снова возьмём $\delta > 0$ такое, что $[\theta_{0} - \delta, \theta_{0} + \delta] \subset \Theta$ и заметим, что если 
    \[
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(A_{n}) 
        = 1, 
        \text{ где } A_{n} 
        = \set{f_{\theta_{0}}(\vec{X}) > f_{\theta_{0} + \delta}(\vec{X}), f_{\theta_{0}}(\vec{X}) > f_{\theta_{0} - \delta}(\vec{X})}.
    \]
    Однако если выполнено $A_{n}$, то внутри $[\theta_{0} - \delta, \theta_{0} + \delta]$ есть точка локального максимума. Как известно, в ней производная равна нулю, и, следовательно, она будет корнем уравнения правдоподобия. Но тогда эта точка есть $\hat{\theta}(\vec{X})$. Далее, это должен быть глобальный максимум, так как иначе найдётся локальный минимум, что противоречит единственности корня. Следовательно, если выполнено $A_{n}$, то $\hat{\theta}(\vec{X})$ есть оценка максимального правдоподобия. Тогда
    \[
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(\hat{\theta}(\vec{X}) = \text{ОМП}) 
        = 1.
    \]
    Но, как известно, $\hat{\theta}(\vec{X})$ есть ближайший к $\theta_{0}$ корень. Тогда для всех $\epsilon > 0$
    \[
        \lim\limits_{n \to \infty} \Pr_{\theta_{0}}(|\hat{\theta}(\vec{X}) - \theta_{0}| \leq \epsilon) 
        = 1.
    \]
    Тем самым получаем, что и ОМП будет состоятельной оценкой параметра $\theta$.
\end{proof}

Поехали дальше. Эти условия регулярности уже далеко не так очевидны на первый взгляд.
\begin{enumerate}[label=(R\arabic*), start=6]
    \item $p_{\theta}(x)$ трижды непрерывно дифференцируема по $\theta$ для всех $x \in A$.
    \item Интеграл
    \[
        \int_{A} p_{\theta}(x)\mu(\dd x)
    \]
    можно дважды дифференцировать под знаком интеграла.
    \item Для всех $\theta \in \Theta$
    \[
        0 < i(\theta) = \EE_{\theta}\left[\left(\pdv{\theta}\ln p_{\theta}(X_{1})\right)^{2}\right] < +\infty.
    \]
    \item Для любого $\theta_{0} \in \Theta$ существует $\delta > 0$ и функция $M(x)$ такая, что для всех $\theta \in [\theta_{0} - \delta, \theta_{0} + \delta]$
    \[
        \left|\pdv[3]{\theta} \ln p_{\theta}(x)\right| \leq M(x), 
        \text{ причём } 
        \EE_{\theta_{0}}[M(X_{1})] < +\infty.
    \]
\end{enumerate}
\begin{theorem}
    В условиях регулярности (R1)"--~(R9) любая состоятельная последовательность $\set{\hat{\theta}_{n}(\vec{X}) \mid n \in \mathbb{N}}$ корней уравнения правдоподобия удовлетворяет свойству асимптотической нормальности: для всех $\theta_{0} \in \Theta$
    \[
        \sqrt{n}(\hat{\theta}_{n}(\vec{X}) - \theta_{0}) 
        \xrightarrow{d_{\theta_{0}}} \mathcal{N}\left(0, \frac{1}{i(\theta_{0})}\right).
    \]
\end{theorem}
\begin{proof}
    Обозначим $\Ell(\vec{X}, \theta) = \ln f_{\theta}(\vec{X})$ и будем говорить, что $\Ell^{(n)}(\vec{X}, \theta)$ есть $n$-я частная производная $\Ell(\vec{X}, \theta)$ по $\theta$. Далее, пусть $\theta_{0}$ есть истинное значение параметра, то есть $\hat{\theta}_{n}(\vec{X})$ сходится к $\theta_{0}$ по вероятности $\Pr_{\theta_{0}}$. Разложим $\Ell'(\vec{X}, \theta)$ в ряд Тейлора в точке $\theta_{0}$:
    \[
        \Ell'(\vec{X}, \theta) 
        = \Ell'(\vec{X}, \theta_{0}) + \Ell''(\vec{X}, \theta_{0})(\theta - \theta_{0}) + \frac{1}{2}\Ell'''(\vec{X}, \tilde{\theta})(\theta - \theta_{0})^{2},
    \]
    где $\tilde{\theta}$ находится между $\theta$ и $\theta_{0}$. Теперь подставим $\theta = \hat{\theta}_{n}(\vec{X})$:
    \[
        \Ell'(\vec{X}, \hat{\theta}_{n}(\vec{X}))
        = \Ell'(\vec{X}, \theta_{0}) + \Ell''(\vec{X}, \theta_{0})(\hat{\theta}_{n}(\vec{X}) - \theta_{0}) + \frac{1}{2}\Ell'''(\vec{X}, \tilde{\theta}_{n})(\hat{\theta}_{n}(\vec{X}) - \theta_{0})^{2},
    \]
    где $\tilde{\theta}_{n}$ находится между $\hat{\theta}_{n}(\vec{X})$ и $\theta_{0}$. Теперь вспомним, что $\hat{\theta}_{n}(\vec{X})$ есть корень уравнения правдоподобия. Тогда $\Ell'(\vec{X}, \hat{\theta}_{n}(\vec{X})) = 0$. Теперь выразим $\sqrt{n}(\hat{\theta}_{n}(\vec{X}) - \theta_{0})$ из данного равенства следующим образом:
    \[
        \sqrt{n}(\hat{\theta}_{n}(\vec{X}) - \theta_{0}) 
        = \frac{-\sqrt{n}\Ell'(\vec{X}, \theta_{0})}{\Ell''(\vec{X}, \theta_{0}) + \frac{1}{2}\Ell'''(\vec{X}, \tilde{\theta})(\hat{\theta}_{n}(\vec{X}) - \theta_{0})}
        = \frac{-\frac{1}{\sqrt{n}}\Ell'(\vec{X}, \theta_{0})}{\frac{1}{n}\Ell''(\vec{X}, \theta_{0}) + \frac{1}{2n}\Ell'''(\vec{X}, \tilde{\theta})(\hat{\theta}_{n}(\vec{X}) - \theta_{0})}
    \]

    Теперь рассмотрим это выражение по частям.
    \begin{itemize}
        \item Начнём с числителя. Заметим, что
        \[
            -\frac{1}{\sqrt{n}}\Ell'(\vec{X}, \theta_{0}) = -\frac{1}{\sqrt{n}}\sum_{i = 1}^{n} \left.\pdv{\theta}\ln p_{\theta}(X_{i})\right|_{\theta = \theta_{0}} = -\sqrt{n}\sum_{i = 1}^{n} U_{\theta_{0}}(X_{i})
        \]
        Как известно, возможность дифференцирования под знаком интеграла показывает, что $\EE_{\theta_{0}}[U_{\theta_{0}}(X_{1})] = 0$. Тогда по центральной предельной теореме
        \[
            -\frac{1}{\sqrt{n}}\sum_{i = 1}^{n} U_{\theta_{0}}(X_{i}) \xrightarrow{d_{\theta_{0}}} -\mathcal{N}\left(0,\DD_{\theta_{0}}[U_{\theta_{0}}(X_{1})]\right) = -\mathcal{N}(0, i(\theta_{0})).
        \]

        \item По усиленному закону больших чисел
        \[
            \frac{1}{n}\Ell''(\vec{X}, \theta_{0}) \xrightarrow{\Pr_{\theta_{0}}\text{-п.н.}} \EE_{\theta_{0}}\left[\left.\pdv[2]{\theta} \ln p_{\theta}(X_{1})\right|_{\theta = \theta_{0}}\right].
        \]
        Докажем, что
        \[
            -\EE_{\theta}\left[\pdv[2]{\theta} \ln p_{\theta}(X_{1})\right] = i(\theta).
        \]
        \begin{proof}
            Заметим, что
            \begin{align*}
                \pdv[2]{\theta} \ln p_{\theta}(x)
                &= \pdv{\theta}\left(\frac{1}{p_{\theta}(x)}\pdv{p_{\theta}(x)}{\theta}\right) 
                = -\frac{1}{(p_{\theta}(x))^{2}}\left(\pdv{p_{\theta}(x)}{\theta}\right)^{2} + \frac{1}{p_{\theta}(x)}\pdv[2]{p_{\theta}(x)}{\theta} \\
                &= -\left(\pdv{\theta} \ln p_{\theta}(x)\right)^{2} + \frac{1}{p_{\theta}(x)}\pdv[2]{p_{\theta}(x)}{\theta}.
            \end{align*}
            Теперь возьмём матожидание и воспользуемся тем, что мы можем два раза дифференцировать под знаком интеграла:
            \begin{align*}
                \EE_{\theta}\left[\pdv[2]{\theta} \ln p_{\theta}(X_{1})\right]
                &= \int_{A} \pdv[2]{\ln p_{\theta}(x)}{\theta}p_{\theta}(x)\mu(\dd x) \\
                &= -\int_{A} \left(\pdv{\ln p_{\theta}(x)}{\theta}\right)^{2}p_{\theta}(x)\mu(\dd x) + \int_{A} \pdv[2]{p_{\theta}(x)}{\theta}\mu(\dd x) \\
                &= -i(\theta) + \pdv[2]{\theta}\int_{A} p_{\theta}(x)\mu(\dd x) = -i(\theta) \qedhere
            \end{align*}
        \end{proof}
        Отсюда получаем, что
        \[
            \frac{1}{n}\Ell''(\vec{X}, \theta_{0}) \xrightarrow{\Pr_{\theta_{0}}\text{-п.н.}} -i(\theta).
        \]

        \item Теперь перейдём к третьему члену и покажем, что он стремится к нулю по вероятности. Заметим, что по условию $\hat{\theta}(\vec{X})$ сходится к $\theta_{0}$ по вероятности. Из этого можно сделать вывод, что $\tilde{\theta}_{n}$ тоже стремится к $\theta_{0}$ по вероятности. Далее, по (R9)
        \[
            \left|\frac{1}{n}\Ell'''(\vec{X}, \theta)\right| \leq \frac{1}{n}\sum_{i = 1}^{n}M(X_{i}),
        \]
        что имеет конечное матожидание. Тогда получаем произведение ограниченной случайной величины на нечто, что сходится к нулю по вероятности. Это сходится к нулю по вероятности.
    \end{itemize}

    Комбинируя вышесказанное, по лемме Слуцкого получаем, что
    \[
        \sqrt{n}(\hat{\theta}_{n}(\vec{X}) - \theta_{0}) \xrightarrow{d_{\theta_{0}}} \frac{1}{i(\theta_{0})}\mathcal{N}(0, i(\theta_{0})) = \mathcal{N}\left(0, \frac{1}{i(\theta_{0})}\right). \qedhere
    \]
\end{proof}
И получаем приятное с практической точки зрения свойство:
\begin{consequence}
    Если в условиях теоремы для всех $\vec{X} = (X_{1}, \ldots, X_{n})$ существует единственное решение уравнения правдоподобия, то оно является оценкой максимального правдоподобия, причём ОМП будет асимптотически нормальной оценкой параметра $\theta$ с асимптотической дисперсией $i^{-1}(\theta)$.
\end{consequence}

Оказывается, что можно предложить нижнюю границу не только для обычной дисперсии (что даёт неравенство Рао-Крамера), но и для асимптотической дисперсии. Этот результат называется \emph{теоремой Бахадура}. Сформулируем его:
\begin{theorem}[Бахадур]
    Если в условиях регулярности (R1)"--~(R9) оценка $\hat{\theta}(\vec{X})$ является асимптотически нормальной оценкой параметра $\theta$ с асимптотической дисперсией $\sigma^{2}(\theta)$, то $\sigma^{2}(\theta) \geq i^{-1}(\theta)$ почти везде (то есть неравенство нарушается только на множестве лебеговой меры 0).
\end{theorem}
Ну и сразу же пример, в котором ограничение выполнено не везде, но почти везде.
\begin{problem}
    Пусть $\vec{X} = (X_{1}, \ldots, X_{n})$ "--- выборка из нормального распределения $\mathcal{N}(\theta, 1)$. Введём следующую оценку параметра $\theta$:
    \[
        \hat{\theta}_{n}(\vec{X})
        = \begin{cases}
            \overline{\vec{X}}, & |\overline{\vec{X}}| \geq n^{-1/4} \\
            \overline{\vec{X}}/2, & |\overline{\vec{X}}| < n^{-1/4}
        \end{cases}
    \]
    Найдите асимптотическую дисперсию $\sigma^{2}(\theta)$ и сравните её с обратной информацией Фишера $i^{-1}(\theta)$ одного элемента. 
\end{problem}
\begin{proof}[Решение]
    Как известно, усиленный закон больших чисел имеет скорость сходимости порядка $\mathcal{O}(n^{-1/2})$ с вероятностью, стремящейся к 1. Тогда если $\theta \neq 0$, то
    \[
        .\lim\limits_{n \to \infty} \Pr_{\theta}(\hat{\theta}_{n}(\vec{X}) = \overline{\vec{X}}) = 1
    \]
    Теперь рассмотрим распределение $\sqrt{n}(\hat{\theta}_{n}(\vec{X}) - \theta)$. Для этого воспользуемся формулой полной вероятности:
    \begin{align*}
        \Pr(\sqrt{n}(\hat{\theta}_{n}(\vec{X}) - \theta) \leq x)
        &= \Pr(\sqrt{n}(\hat{\theta}_{n}(\vec{X}) - \theta) \leq x \mid \hat{\theta}_{n}(\vec{X}) = \overline{\vec{X}})\Pr(\hat{\theta}_{n}(\vec{X}) = \overline{\vec{X}}) \\
        &\phantom{=}+ \Pr(\sqrt{n}(\hat{\theta}_{n}(\vec{X}) - \theta) \leq x \mid \hat{\theta}_{n}(\vec{X}) = \overline{\vec{X}}/2)\Pr(\hat{\theta}_{n}(\vec{X}) = \overline{\vec{X}}/2) \\
        &= \Pr(\sqrt{n}(\overline{\vec{X}} - \theta) \leq x)\Pr(\hat{\theta}_{n}(\vec{X}) = \overline{\vec{X}}) \\
        &\phantom{=}+ \Pr(\sqrt{n}(\overline{\vec{X}}/2 - \theta) \leq x)\Pr(\hat{\theta}_{n}(\vec{X}) = \overline{\vec{X}}/2)
    \end{align*}
    Теперь устремим $n$ к бесконечности. Согласно результату выше и центральной предельной теореме получаем, что
    \[
        \lim\limits_{n \to \infty} \Pr(\sqrt{n}(\hat{\theta}_{n}(\vec{X}) - \theta) \leq x)
        = \Pr(\mathcal{N}(0, 1) \leq x) = \Phi(x) 
        \implies
        \sqrt{n}(\hat{\theta}_{n}(\vec{X}) - \theta) \xrightarrow{d_{\theta}} \mathcal{N}(0, 1).
    \]

    Далее скажем, что пусть $\theta = 0$. В таком случае утверждение о скорости сходимости усиленного закона больших чисел говорит, что
    \[
        \lim\limits_{n \to \infty} \Pr_{\theta}(\hat{\theta}_{n}(\vec{X}) = \overline{\vec{X}}/2) = 1.
    \]
    Применяя формулу полной вероятности, получаем, что
    \[
        \Pr(\sqrt{n}(\hat{\theta}_{n}(\vec{X}) - \theta) \leq x)
        = \Pr(\sqrt{n}\,\overline{\vec{X}} \leq x)\Pr(\hat{\theta}_{n}(\vec{X}) = \overline{\vec{X}}) + \Pr(\sqrt{n}\,\overline{\vec{X}} \leq 2x)\Pr(\hat{\theta}_{n}(\vec{X}) = \overline{\vec{X}}/2).
    \]
    Следовательно,
    \[
        \lim\limits_{n \to \infty} \Pr(\sqrt{n}(\hat{\theta}_{n}(\vec{X}) - \theta) \leq x) = \Phi(2x)
        \implies
        \sqrt{n}(\hat{\theta}_{n}(\vec{X}) - \theta) \xrightarrow{d_{\theta}} \mathcal{N}(0, 1/4).
    \]
    Однако информация Фишера равна
    \[
        i(\theta) = \EE_{\theta}[(X_{1} - \theta)^{2}] = \DD_{\theta}[X_{1}] = 1.
    \]
    Тогда мы получаем, что везде, кроме нуля, $\sigma^{2}(\theta) \geq i^{-1}(\theta)$.
\end{proof}